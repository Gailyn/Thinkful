{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With banks processing billions of transactions each day, it becomes a challenge detecting which of those are fraudulent. Fortunatly machine learning techniques can aid in effective detection and in this project I develop an algorithm to predict fraud. To accomplish this task, I use a dataset obtained from Kaggle and uploaded by the ULB Machine Learning Group. \n",
    "This dataset contains 284,807 anonymized transactions from 2013, containing a number of fraudulent transactions.Features components transfromed using PCA with the exception of ‘Time’, ‘Amount’, and ‘Class’. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. Feature 'Class' is my desired target variable and it takes value 1 in case of fraud and 0 otherwise. In this project, I test several different supervised learning models for the most accurate detection of fraudulent transactions, including: \n",
    "- Native Bayes Classifier\n",
    "- Knn classifier\n",
    "- Random Forest\n",
    "- Decision tree \n",
    "- Logistic regression \n",
    "- Svm classifier \n",
    "- Gradient boosted classifier \n",
    "\n",
    "I use gridsearch cv to find the ideal parameters for each of the classifiers I use. I also use a  number of different metrics to evaluate the performance of each of the models. The AUC and ROC plots reveal the positive to false positive rate and helps visually compare the effectiveness of the classifier. I use holdout grouping, cross-validation, and run classification reports on each of the models. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.791855</td>\n",
       "      <td>-0.327771</td>\n",
       "      <td>1.641750</td>\n",
       "      <td>1.767473</td>\n",
       "      <td>-0.136588</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>-0.422911</td>\n",
       "      <td>-1.907107</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151663</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>1.020586</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>-0.235557</td>\n",
       "      <td>-0.164778</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>15.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-5.401258</td>\n",
       "      <td>-5.450148</td>\n",
       "      <td>1.186305</td>\n",
       "      <td>1.736239</td>\n",
       "      <td>3.049106</td>\n",
       "      <td>-1.763406</td>\n",
       "      <td>-1.559738</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503600</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>2.458589</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>-0.481631</td>\n",
       "      <td>-0.621272</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.949594</td>\n",
       "      <td>46.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.492936</td>\n",
       "      <td>-1.029346</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-1.555434</td>\n",
       "      <td>-0.720961</td>\n",
       "      <td>-1.080664</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-1.978682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.175074</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.694885</td>\n",
       "      <td>-1.361819</td>\n",
       "      <td>1.029221</td>\n",
       "      <td>0.834159</td>\n",
       "      <td>-1.191209</td>\n",
       "      <td>1.309109</td>\n",
       "      <td>-0.878586</td>\n",
       "      <td>0.445290</td>\n",
       "      <td>-0.446196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295583</td>\n",
       "      <td>-0.571955</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>-0.422234</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>231.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>34.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1.166616</td>\n",
       "      <td>0.502120</td>\n",
       "      <td>-0.067300</td>\n",
       "      <td>2.261569</td>\n",
       "      <td>0.428804</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.241147</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>-0.989162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>-0.061972</td>\n",
       "      <td>-0.103855</td>\n",
       "      <td>-0.370415</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>0.108556</td>\n",
       "      <td>-0.040521</td>\n",
       "      <td>-0.011418</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>...</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-1.946525</td>\n",
       "      <td>-0.044901</td>\n",
       "      <td>-0.405570</td>\n",
       "      <td>-1.013057</td>\n",
       "      <td>2.941968</td>\n",
       "      <td>2.955053</td>\n",
       "      <td>-0.063063</td>\n",
       "      <td>0.855546</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579526</td>\n",
       "      <td>-0.799229</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.983421</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>0.707519</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-2.074295</td>\n",
       "      <td>-0.121482</td>\n",
       "      <td>1.322021</td>\n",
       "      <td>0.410008</td>\n",
       "      <td>0.295198</td>\n",
       "      <td>-0.959537</td>\n",
       "      <td>0.543985</td>\n",
       "      <td>-0.104627</td>\n",
       "      <td>0.475664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403639</td>\n",
       "      <td>-0.227404</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.398535</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>0.274404</td>\n",
       "      <td>0.359969</td>\n",
       "      <td>0.243232</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.173285</td>\n",
       "      <td>0.353498</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>1.133563</td>\n",
       "      <td>-0.172577</td>\n",
       "      <td>-0.916054</td>\n",
       "      <td>0.369025</td>\n",
       "      <td>-0.327260</td>\n",
       "      <td>-0.246651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.227812</td>\n",
       "      <td>-0.150487</td>\n",
       "      <td>0.435045</td>\n",
       "      <td>0.724825</td>\n",
       "      <td>-0.337082</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>41.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.322707</td>\n",
       "      <td>-0.174041</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>0.576038</td>\n",
       "      <td>-0.836758</td>\n",
       "      <td>-0.831083</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.220982</td>\n",
       "      <td>-1.071425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>-0.323357</td>\n",
       "      <td>-0.037710</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>-0.280158</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-0.414289</td>\n",
       "      <td>0.905437</td>\n",
       "      <td>1.727453</td>\n",
       "      <td>1.473471</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.200331</td>\n",
       "      <td>0.740228</td>\n",
       "      <td>-0.029247</td>\n",
       "      <td>-0.593392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.457331</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.642522</td>\n",
       "      <td>-0.183891</td>\n",
       "      <td>-0.277464</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.152665</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23.0</td>\n",
       "      <td>1.059387</td>\n",
       "      <td>-0.175319</td>\n",
       "      <td>1.266130</td>\n",
       "      <td>1.186110</td>\n",
       "      <td>-0.786002</td>\n",
       "      <td>0.578435</td>\n",
       "      <td>-0.767084</td>\n",
       "      <td>0.401046</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.213734</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.294638</td>\n",
       "      <td>-0.395070</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284777</th>\n",
       "      <td>172764.0</td>\n",
       "      <td>2.079137</td>\n",
       "      <td>-0.028723</td>\n",
       "      <td>-1.343392</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-1.345452</td>\n",
       "      <td>0.227476</td>\n",
       "      <td>-0.378355</td>\n",
       "      <td>0.665911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235758</td>\n",
       "      <td>0.829758</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>-0.105327</td>\n",
       "      <td>-0.022363</td>\n",
       "      <td>-0.060283</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284778</th>\n",
       "      <td>172764.0</td>\n",
       "      <td>-0.764523</td>\n",
       "      <td>0.588379</td>\n",
       "      <td>-0.907599</td>\n",
       "      <td>-0.418847</td>\n",
       "      <td>0.901528</td>\n",
       "      <td>-0.760802</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.414698</td>\n",
       "      <td>-0.730854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>-0.431876</td>\n",
       "      <td>0.141759</td>\n",
       "      <td>0.587119</td>\n",
       "      <td>-0.200998</td>\n",
       "      <td>0.267337</td>\n",
       "      <td>-0.152951</td>\n",
       "      <td>-0.065285</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284779</th>\n",
       "      <td>172766.0</td>\n",
       "      <td>1.975178</td>\n",
       "      <td>-0.616244</td>\n",
       "      <td>-2.628295</td>\n",
       "      <td>-0.406246</td>\n",
       "      <td>2.327804</td>\n",
       "      <td>3.664740</td>\n",
       "      <td>-0.533297</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>1.128798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086043</td>\n",
       "      <td>0.543613</td>\n",
       "      <td>-0.032129</td>\n",
       "      <td>0.768379</td>\n",
       "      <td>0.477688</td>\n",
       "      <td>-0.031833</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.066542</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284780</th>\n",
       "      <td>172766.0</td>\n",
       "      <td>-1.727503</td>\n",
       "      <td>1.108356</td>\n",
       "      <td>2.219561</td>\n",
       "      <td>1.148583</td>\n",
       "      <td>-0.884199</td>\n",
       "      <td>0.793083</td>\n",
       "      <td>-0.527298</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.853819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094708</td>\n",
       "      <td>0.236818</td>\n",
       "      <td>-0.204280</td>\n",
       "      <td>1.158185</td>\n",
       "      <td>0.627801</td>\n",
       "      <td>-0.399981</td>\n",
       "      <td>0.510818</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>172766.0</td>\n",
       "      <td>-1.139015</td>\n",
       "      <td>-0.155510</td>\n",
       "      <td>1.894478</td>\n",
       "      <td>-1.138957</td>\n",
       "      <td>1.451777</td>\n",
       "      <td>0.093598</td>\n",
       "      <td>0.191353</td>\n",
       "      <td>0.092211</td>\n",
       "      <td>-0.062621</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191027</td>\n",
       "      <td>-0.631658</td>\n",
       "      <td>-0.147249</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>-0.241068</td>\n",
       "      <td>-0.161717</td>\n",
       "      <td>-0.149188</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284782</th>\n",
       "      <td>172767.0</td>\n",
       "      <td>-0.268061</td>\n",
       "      <td>2.540315</td>\n",
       "      <td>-1.400915</td>\n",
       "      <td>4.846661</td>\n",
       "      <td>0.639105</td>\n",
       "      <td>0.186479</td>\n",
       "      <td>-0.045911</td>\n",
       "      <td>0.936448</td>\n",
       "      <td>-2.419986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263889</td>\n",
       "      <td>-0.857904</td>\n",
       "      <td>0.235172</td>\n",
       "      <td>-0.681794</td>\n",
       "      <td>-0.668894</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>-0.066751</td>\n",
       "      <td>-0.072447</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284783</th>\n",
       "      <td>172768.0</td>\n",
       "      <td>-1.796092</td>\n",
       "      <td>1.929178</td>\n",
       "      <td>-2.828417</td>\n",
       "      <td>-1.689844</td>\n",
       "      <td>2.199572</td>\n",
       "      <td>3.123732</td>\n",
       "      <td>-0.270714</td>\n",
       "      <td>1.657495</td>\n",
       "      <td>0.465804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271170</td>\n",
       "      <td>1.145750</td>\n",
       "      <td>0.084783</td>\n",
       "      <td>0.721269</td>\n",
       "      <td>-0.529906</td>\n",
       "      <td>-0.240117</td>\n",
       "      <td>0.129126</td>\n",
       "      <td>-0.080620</td>\n",
       "      <td>11.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284784</th>\n",
       "      <td>172768.0</td>\n",
       "      <td>-0.669662</td>\n",
       "      <td>0.923769</td>\n",
       "      <td>-1.543167</td>\n",
       "      <td>-1.560729</td>\n",
       "      <td>2.833960</td>\n",
       "      <td>3.240843</td>\n",
       "      <td>0.181576</td>\n",
       "      <td>1.282746</td>\n",
       "      <td>-0.893890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183856</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>-0.373023</td>\n",
       "      <td>0.651122</td>\n",
       "      <td>1.073823</td>\n",
       "      <td>0.844590</td>\n",
       "      <td>-0.286676</td>\n",
       "      <td>-0.187719</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284785</th>\n",
       "      <td>172768.0</td>\n",
       "      <td>0.032887</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>-1.185844</td>\n",
       "      <td>-1.729828</td>\n",
       "      <td>2.932315</td>\n",
       "      <td>3.401529</td>\n",
       "      <td>0.337434</td>\n",
       "      <td>0.925377</td>\n",
       "      <td>-0.165663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266113</td>\n",
       "      <td>-0.716336</td>\n",
       "      <td>0.108519</td>\n",
       "      <td>0.688519</td>\n",
       "      <td>-0.460220</td>\n",
       "      <td>0.161939</td>\n",
       "      <td>0.265368</td>\n",
       "      <td>0.090245</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284786</th>\n",
       "      <td>172768.0</td>\n",
       "      <td>-2.076175</td>\n",
       "      <td>2.142238</td>\n",
       "      <td>-2.522704</td>\n",
       "      <td>-1.888063</td>\n",
       "      <td>1.982785</td>\n",
       "      <td>3.732950</td>\n",
       "      <td>-1.217430</td>\n",
       "      <td>-0.536644</td>\n",
       "      <td>0.272867</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016666</td>\n",
       "      <td>-1.588269</td>\n",
       "      <td>0.588482</td>\n",
       "      <td>0.632444</td>\n",
       "      <td>-0.201064</td>\n",
       "      <td>0.199251</td>\n",
       "      <td>0.438657</td>\n",
       "      <td>0.172923</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284787</th>\n",
       "      <td>172769.0</td>\n",
       "      <td>-1.029719</td>\n",
       "      <td>-1.110670</td>\n",
       "      <td>-0.636179</td>\n",
       "      <td>-0.840816</td>\n",
       "      <td>2.424360</td>\n",
       "      <td>-2.956733</td>\n",
       "      <td>0.283610</td>\n",
       "      <td>-0.332656</td>\n",
       "      <td>-0.247488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353722</td>\n",
       "      <td>0.488487</td>\n",
       "      <td>0.293632</td>\n",
       "      <td>0.107812</td>\n",
       "      <td>-0.935586</td>\n",
       "      <td>1.138216</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0.255347</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>172770.0</td>\n",
       "      <td>2.007418</td>\n",
       "      <td>-0.280235</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>0.335261</td>\n",
       "      <td>-0.715798</td>\n",
       "      <td>-0.751373</td>\n",
       "      <td>-0.458972</td>\n",
       "      <td>-0.140140</td>\n",
       "      <td>0.959971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208260</td>\n",
       "      <td>-0.430347</td>\n",
       "      <td>0.416765</td>\n",
       "      <td>0.064819</td>\n",
       "      <td>-0.608337</td>\n",
       "      <td>0.268436</td>\n",
       "      <td>-0.028069</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284789</th>\n",
       "      <td>172770.0</td>\n",
       "      <td>-0.446951</td>\n",
       "      <td>1.302212</td>\n",
       "      <td>-0.168583</td>\n",
       "      <td>0.981577</td>\n",
       "      <td>0.578957</td>\n",
       "      <td>-0.605641</td>\n",
       "      <td>1.253430</td>\n",
       "      <td>-1.042610</td>\n",
       "      <td>-0.417116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.305268</td>\n",
       "      <td>-0.148093</td>\n",
       "      <td>-0.038712</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>-0.362666</td>\n",
       "      <td>0.503092</td>\n",
       "      <td>0.229921</td>\n",
       "      <td>60.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284790</th>\n",
       "      <td>172771.0</td>\n",
       "      <td>-0.515513</td>\n",
       "      <td>0.971950</td>\n",
       "      <td>-1.014580</td>\n",
       "      <td>-0.677037</td>\n",
       "      <td>0.912430</td>\n",
       "      <td>-0.316187</td>\n",
       "      <td>0.396137</td>\n",
       "      <td>0.532364</td>\n",
       "      <td>-0.224606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280302</td>\n",
       "      <td>-0.849919</td>\n",
       "      <td>0.300245</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.376379</td>\n",
       "      <td>0.128660</td>\n",
       "      <td>-0.015205</td>\n",
       "      <td>-0.021486</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284791</th>\n",
       "      <td>172774.0</td>\n",
       "      <td>-0.863506</td>\n",
       "      <td>0.874701</td>\n",
       "      <td>0.420358</td>\n",
       "      <td>-0.530365</td>\n",
       "      <td>0.356561</td>\n",
       "      <td>-1.046238</td>\n",
       "      <td>0.757051</td>\n",
       "      <td>0.230473</td>\n",
       "      <td>-0.506856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108846</td>\n",
       "      <td>-0.480820</td>\n",
       "      <td>-0.074513</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>-0.113149</td>\n",
       "      <td>0.280378</td>\n",
       "      <td>-0.077310</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>20.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284792</th>\n",
       "      <td>172774.0</td>\n",
       "      <td>-0.724123</td>\n",
       "      <td>1.485216</td>\n",
       "      <td>-1.132218</td>\n",
       "      <td>-0.607190</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>-0.482638</td>\n",
       "      <td>0.548393</td>\n",
       "      <td>0.343003</td>\n",
       "      <td>-0.226323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414621</td>\n",
       "      <td>1.307511</td>\n",
       "      <td>-0.059545</td>\n",
       "      <td>0.242669</td>\n",
       "      <td>-0.665424</td>\n",
       "      <td>-0.269869</td>\n",
       "      <td>-0.170579</td>\n",
       "      <td>-0.030692</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284793</th>\n",
       "      <td>172775.0</td>\n",
       "      <td>1.971002</td>\n",
       "      <td>-0.699067</td>\n",
       "      <td>-1.697541</td>\n",
       "      <td>-0.617643</td>\n",
       "      <td>1.718797</td>\n",
       "      <td>3.911336</td>\n",
       "      <td>-1.259306</td>\n",
       "      <td>1.056209</td>\n",
       "      <td>1.315006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188758</td>\n",
       "      <td>0.694418</td>\n",
       "      <td>0.163002</td>\n",
       "      <td>0.726365</td>\n",
       "      <td>-0.058282</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>0.061858</td>\n",
       "      <td>-0.043716</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284794</th>\n",
       "      <td>172777.0</td>\n",
       "      <td>-1.266580</td>\n",
       "      <td>-0.400461</td>\n",
       "      <td>0.956221</td>\n",
       "      <td>-0.723919</td>\n",
       "      <td>1.531993</td>\n",
       "      <td>-1.788600</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157831</td>\n",
       "      <td>-0.883365</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>-0.076790</td>\n",
       "      <td>-0.095833</td>\n",
       "      <td>0.132720</td>\n",
       "      <td>-0.028468</td>\n",
       "      <td>0.126494</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284795</th>\n",
       "      <td>172778.0</td>\n",
       "      <td>-12.516732</td>\n",
       "      <td>10.187818</td>\n",
       "      <td>-8.476671</td>\n",
       "      <td>-2.510473</td>\n",
       "      <td>-4.586669</td>\n",
       "      <td>-1.394465</td>\n",
       "      <td>-3.632516</td>\n",
       "      <td>5.498583</td>\n",
       "      <td>4.893089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944759</td>\n",
       "      <td>-1.565026</td>\n",
       "      <td>0.890675</td>\n",
       "      <td>-1.253276</td>\n",
       "      <td>1.786717</td>\n",
       "      <td>0.320763</td>\n",
       "      <td>2.090712</td>\n",
       "      <td>1.232864</td>\n",
       "      <td>9.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284796</th>\n",
       "      <td>172780.0</td>\n",
       "      <td>1.884849</td>\n",
       "      <td>-0.143540</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>1.506772</td>\n",
       "      <td>-0.035300</td>\n",
       "      <td>-0.613638</td>\n",
       "      <td>0.190241</td>\n",
       "      <td>-0.249058</td>\n",
       "      <td>0.666458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144008</td>\n",
       "      <td>0.634646</td>\n",
       "      <td>-0.042114</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>0.316403</td>\n",
       "      <td>-0.461441</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>-0.041068</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284797</th>\n",
       "      <td>172782.0</td>\n",
       "      <td>-0.241923</td>\n",
       "      <td>0.712247</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>-0.463406</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>-1.343668</td>\n",
       "      <td>0.929369</td>\n",
       "      <td>-0.206210</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228876</td>\n",
       "      <td>-0.514376</td>\n",
       "      <td>0.279598</td>\n",
       "      <td>0.371441</td>\n",
       "      <td>-0.559238</td>\n",
       "      <td>0.113144</td>\n",
       "      <td>0.131507</td>\n",
       "      <td>0.081265</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284798</th>\n",
       "      <td>172782.0</td>\n",
       "      <td>0.219529</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-0.635891</td>\n",
       "      <td>0.960928</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-1.014307</td>\n",
       "      <td>0.427126</td>\n",
       "      <td>0.121340</td>\n",
       "      <td>-0.285670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099936</td>\n",
       "      <td>0.337120</td>\n",
       "      <td>0.251791</td>\n",
       "      <td>0.057688</td>\n",
       "      <td>-1.508368</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.181205</td>\n",
       "      <td>0.215243</td>\n",
       "      <td>24.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284799</th>\n",
       "      <td>172783.0</td>\n",
       "      <td>-1.775135</td>\n",
       "      <td>-0.004235</td>\n",
       "      <td>1.189786</td>\n",
       "      <td>0.331096</td>\n",
       "      <td>1.196063</td>\n",
       "      <td>5.519980</td>\n",
       "      <td>-1.518185</td>\n",
       "      <td>2.080825</td>\n",
       "      <td>1.159498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.654850</td>\n",
       "      <td>-0.348929</td>\n",
       "      <td>0.745323</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>-0.127579</td>\n",
       "      <td>0.454379</td>\n",
       "      <td>0.130308</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>172784.0</td>\n",
       "      <td>2.039560</td>\n",
       "      <td>-0.175233</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.234580</td>\n",
       "      <td>-0.008713</td>\n",
       "      <td>-0.726571</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>-0.118228</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268048</td>\n",
       "      <td>-0.717211</td>\n",
       "      <td>0.297930</td>\n",
       "      <td>-0.359769</td>\n",
       "      <td>-0.315610</td>\n",
       "      <td>0.201114</td>\n",
       "      <td>-0.080826</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>172785.0</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>-0.546012</td>\n",
       "      <td>-0.745097</td>\n",
       "      <td>1.130314</td>\n",
       "      <td>-0.235973</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314205</td>\n",
       "      <td>-0.808520</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>-0.435870</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "5            2.0  -0.425966   0.960523  1.141109 -0.168252  0.420987   \n",
       "6            4.0   1.229658   0.141004  0.045371  1.202613  0.191881   \n",
       "7            7.0  -0.644269   1.417964  1.074380 -0.492199  0.948934   \n",
       "8            7.0  -0.894286   0.286157 -0.113192 -0.271526  2.669599   \n",
       "9            9.0  -0.338262   1.119593  1.044367 -0.222187  0.499361   \n",
       "10          10.0   1.449044  -1.176339  0.913860 -1.375667 -1.971383   \n",
       "11          10.0   0.384978   0.616109 -0.874300 -0.094019  2.924584   \n",
       "12          10.0   1.249999  -1.221637  0.383930 -1.234899 -1.485419   \n",
       "13          11.0   1.069374   0.287722  0.828613  2.712520 -0.178398   \n",
       "14          12.0  -2.791855  -0.327771  1.641750  1.767473 -0.136588   \n",
       "15          12.0  -0.752417   0.345485  2.057323 -1.468643 -1.158394   \n",
       "16          12.0   1.103215  -0.040296  1.267332  1.289091 -0.735997   \n",
       "17          13.0  -0.436905   0.918966  0.924591 -0.727219  0.915679   \n",
       "18          14.0  -5.401258  -5.450148  1.186305  1.736239  3.049106   \n",
       "19          15.0   1.492936  -1.029346  0.454795 -1.438026 -1.555434   \n",
       "20          16.0   0.694885  -1.361819  1.029221  0.834159 -1.191209   \n",
       "21          17.0   0.962496   0.328461 -0.171479  2.109204  1.129566   \n",
       "22          18.0   1.166616   0.502120 -0.067300  2.261569  0.428804   \n",
       "23          18.0   0.247491   0.277666  1.185471 -0.092603 -1.314394   \n",
       "24          22.0  -1.946525  -0.044901 -0.405570 -1.013057  2.941968   \n",
       "25          22.0  -2.074295  -0.121482  1.322021  0.410008  0.295198   \n",
       "26          23.0   1.173285   0.353498  0.283905  1.133563 -0.172577   \n",
       "27          23.0   1.322707  -0.174041  0.434555  0.576038 -0.836758   \n",
       "28          23.0  -0.414289   0.905437  1.727453  1.473471  0.007443   \n",
       "29          23.0   1.059387  -0.175319  1.266130  1.186110 -0.786002   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284777  172764.0   2.079137  -0.028723 -1.343392  0.358000 -0.045791   \n",
       "284778  172764.0  -0.764523   0.588379 -0.907599 -0.418847  0.901528   \n",
       "284779  172766.0   1.975178  -0.616244 -2.628295 -0.406246  2.327804   \n",
       "284780  172766.0  -1.727503   1.108356  2.219561  1.148583 -0.884199   \n",
       "284781  172766.0  -1.139015  -0.155510  1.894478 -1.138957  1.451777   \n",
       "284782  172767.0  -0.268061   2.540315 -1.400915  4.846661  0.639105   \n",
       "284783  172768.0  -1.796092   1.929178 -2.828417 -1.689844  2.199572   \n",
       "284784  172768.0  -0.669662   0.923769 -1.543167 -1.560729  2.833960   \n",
       "284785  172768.0   0.032887   0.545338 -1.185844 -1.729828  2.932315   \n",
       "284786  172768.0  -2.076175   2.142238 -2.522704 -1.888063  1.982785   \n",
       "284787  172769.0  -1.029719  -1.110670 -0.636179 -0.840816  2.424360   \n",
       "284788  172770.0   2.007418  -0.280235 -0.208113  0.335261 -0.715798   \n",
       "284789  172770.0  -0.446951   1.302212 -0.168583  0.981577  0.578957   \n",
       "284790  172771.0  -0.515513   0.971950 -1.014580 -0.677037  0.912430   \n",
       "284791  172774.0  -0.863506   0.874701  0.420358 -0.530365  0.356561   \n",
       "284792  172774.0  -0.724123   1.485216 -1.132218 -0.607190  0.709499   \n",
       "284793  172775.0   1.971002  -0.699067 -1.697541 -0.617643  1.718797   \n",
       "284794  172777.0  -1.266580  -0.400461  0.956221 -0.723919  1.531993   \n",
       "284795  172778.0 -12.516732  10.187818 -8.476671 -2.510473 -4.586669   \n",
       "284796  172780.0   1.884849  -0.143540 -0.999943  1.506772 -0.035300   \n",
       "284797  172782.0  -0.241923   0.712247  0.399806 -0.463406  0.244531   \n",
       "284798  172782.0   0.219529   0.881246 -0.635891  0.960928 -0.152971   \n",
       "284799  172783.0  -1.775135  -0.004235  1.189786  0.331096  1.196063   \n",
       "284800  172784.0   2.039560  -0.175233 -1.196825  0.234580 -0.008713   \n",
       "284801  172785.0   0.120316   0.931005 -0.546012 -0.745097  1.130314   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...         V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...   -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ...   -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...    0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ...   -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...   -0.009431  0.798278   \n",
       "5      -0.029728  0.476201  0.260314 -0.568671  ...   -0.208254 -0.559825   \n",
       "6       0.272708 -0.005159  0.081213  0.464960  ...   -0.167716 -0.270710   \n",
       "7       0.428118  1.120631 -3.807864  0.615375  ...    1.943465 -1.015455   \n",
       "8       3.721818  0.370145  0.851084 -0.392048  ...   -0.073425 -0.268092   \n",
       "9      -0.246761  0.651583  0.069539 -0.736727  ...   -0.246914 -0.633753   \n",
       "10     -0.629152 -1.423236  0.048456 -1.720408  ...   -0.009302  0.313894   \n",
       "11      3.317027  0.470455  0.538247 -0.558895  ...    0.049924  0.238422   \n",
       "12     -0.753230 -0.689405 -0.227487 -2.094011  ...   -0.231809 -0.483285   \n",
       "13      0.337544 -0.096717  0.115982 -0.221083  ...   -0.036876  0.074412   \n",
       "14      0.807596 -0.422911 -1.907107  0.755713  ...    1.151663  0.222182   \n",
       "15     -0.077850 -0.608581  0.003603 -0.436167  ...    0.499625  1.353650   \n",
       "16      0.288069 -0.586057  0.189380  0.782333  ...   -0.024612  0.196002   \n",
       "17     -0.127867  0.707642  0.087962 -0.665271  ...   -0.194796 -0.672638   \n",
       "18     -1.763406 -1.559738  0.160842  1.233090  ...   -0.503600  0.984460   \n",
       "19     -0.720961 -1.080664 -0.053127 -1.978682  ...   -0.177650 -0.175074   \n",
       "20      1.309109 -0.878586  0.445290 -0.446196  ...   -0.295583 -0.571955   \n",
       "21      1.696038  0.107712  0.521502 -1.191311  ...    0.143997  0.402492   \n",
       "22      0.089474  0.241147  0.138082 -0.989162  ...    0.018702 -0.061972   \n",
       "23     -0.150116 -0.946365 -1.617935  1.544071  ...    1.650180  0.200454   \n",
       "24      2.955053 -0.063063  0.855546  0.049967  ...   -0.579526 -0.799229   \n",
       "25     -0.959537  0.543985 -0.104627  0.475664  ...   -0.403639 -0.227404   \n",
       "26     -0.916054  0.369025 -0.327260 -0.246651  ...    0.067003  0.227812   \n",
       "27     -0.831083 -0.264905 -0.220982 -1.071425  ...   -0.284376 -0.323357   \n",
       "28     -0.200331  0.740228 -0.029247 -0.593392  ...    0.077237  0.457331   \n",
       "29      0.578435 -0.767084  0.401046  0.699500  ...    0.013676  0.213734   \n",
       "...          ...       ...       ...       ...  ...         ...       ...   \n",
       "284777 -1.345452  0.227476 -0.378355  0.665911  ...    0.235758  0.829758   \n",
       "284778 -0.760802  0.758545  0.414698 -0.730854  ...    0.003530 -0.431876   \n",
       "284779  3.664740 -0.533297  0.842937  1.128798  ...    0.086043  0.543613   \n",
       "284780  0.793083 -0.527298  0.866429  0.853819  ...   -0.094708  0.236818   \n",
       "284781  0.093598  0.191353  0.092211 -0.062621  ...   -0.191027 -0.631658   \n",
       "284782  0.186479 -0.045911  0.936448 -2.419986  ...   -0.263889 -0.857904   \n",
       "284783  3.123732 -0.270714  1.657495  0.465804  ...    0.271170  1.145750   \n",
       "284784  3.240843  0.181576  1.282746 -0.893890  ...    0.183856  0.202670   \n",
       "284785  3.401529  0.337434  0.925377 -0.165663  ...   -0.266113 -0.716336   \n",
       "284786  3.732950 -1.217430 -0.536644  0.272867  ...    2.016666 -1.588269   \n",
       "284787 -2.956733  0.283610 -0.332656 -0.247488  ...    0.353722  0.488487   \n",
       "284788 -0.751373 -0.458972 -0.140140  0.959971  ...   -0.208260 -0.430347   \n",
       "284789 -0.605641  1.253430 -1.042610 -0.417116  ...    0.851800  0.305268   \n",
       "284790 -0.316187  0.396137  0.532364 -0.224606  ...   -0.280302 -0.849919   \n",
       "284791 -1.046238  0.757051  0.230473 -0.506856  ...   -0.108846 -0.480820   \n",
       "284792 -0.482638  0.548393  0.343003 -0.226323  ...    0.414621  1.307511   \n",
       "284793  3.911336 -1.259306  1.056209  1.315006  ...    0.188758  0.694418   \n",
       "284794 -1.788600  0.314741  0.004704  0.013857  ...   -0.157831 -0.883365   \n",
       "284795 -1.394465 -3.632516  5.498583  4.893089  ...   -0.944759 -1.565026   \n",
       "284796 -0.613638  0.190241 -0.249058  0.666458  ...    0.144008  0.634646   \n",
       "284797 -1.343668  0.929369 -0.206210  0.106234  ...   -0.228876 -0.514376   \n",
       "284798 -1.014307  0.427126  0.121340 -0.285670  ...    0.099936  0.337120   \n",
       "284799  5.519980 -1.518185  2.080825  1.159498  ...    0.103302  0.654850   \n",
       "284800 -0.726571  0.017050 -0.118228  0.435402  ...   -0.268048 -0.717211   \n",
       "284801 -0.235973  0.812722  0.115093 -0.204064  ...   -0.314205 -0.808520   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...    0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...    0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...    0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...    0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...    0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "5      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67   \n",
       "6      -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99   \n",
       "7       0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   40.80   \n",
       "8      -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   93.20   \n",
       "9      -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076    3.68   \n",
       "10      0.027740  0.500512  0.251367 -0.129478  0.042850  0.016253    7.80   \n",
       "11      0.009130  0.996710 -0.767315 -0.492208  0.042472 -0.054337    9.99   \n",
       "12      0.084668  0.392831  0.161135 -0.354990  0.026416  0.042422  121.50   \n",
       "13     -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293   27.50   \n",
       "14      1.020586  0.028317 -0.232746 -0.235557 -0.164778 -0.030154   58.80   \n",
       "15     -0.256573 -0.065084 -0.039124 -0.087086 -0.180998  0.129394   15.99   \n",
       "16      0.013802  0.103758  0.364298 -0.382261  0.092809  0.037051   12.99   \n",
       "17     -0.156858 -0.888386 -0.342413 -0.049027  0.079692  0.131024    0.89   \n",
       "18      2.458589  0.042119 -0.481631 -0.621272  0.392053  0.949594   46.80   \n",
       "19      0.040002  0.295814  0.332931 -0.220385  0.022298  0.007602    5.00   \n",
       "20     -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.71   \n",
       "21     -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605   34.09   \n",
       "22     -0.103855 -0.370415  0.603200  0.108556 -0.040521 -0.011418    2.28   \n",
       "23     -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75   \n",
       "24      0.870300  0.983421  0.321201  0.149650  0.707519  0.014600    0.89   \n",
       "25      0.742435  0.398535  0.249212  0.274404  0.359969  0.243232   26.43   \n",
       "26     -0.150487  0.435045  0.724825 -0.337082  0.016368  0.030041   41.88   \n",
       "27     -0.037710  0.347151  0.559639 -0.280158  0.042335  0.028822   16.00   \n",
       "28     -0.038500  0.642522 -0.183891 -0.277464  0.182687  0.152665   33.00   \n",
       "29      0.014462  0.002951  0.294638 -0.395070  0.081461  0.024220   12.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284777 -0.002063  0.001344  0.262183 -0.105327 -0.022363 -0.060283    1.00   \n",
       "284778  0.141759  0.587119 -0.200998  0.267337 -0.152951 -0.065285   80.00   \n",
       "284779 -0.032129  0.768379  0.477688 -0.031833  0.014151 -0.066542   25.00   \n",
       "284780 -0.204280  1.158185  0.627801 -0.399981  0.510818  0.233265   30.00   \n",
       "284781 -0.147249  0.212931  0.354257 -0.241068 -0.161717 -0.149188   13.00   \n",
       "284782  0.235172 -0.681794 -0.668894  0.044657 -0.066751 -0.072447   12.82   \n",
       "284783  0.084783  0.721269 -0.529906 -0.240117  0.129126 -0.080620   11.46   \n",
       "284784 -0.373023  0.651122  1.073823  0.844590 -0.286676 -0.187719   40.00   \n",
       "284785  0.108519  0.688519 -0.460220  0.161939  0.265368  0.090245    1.79   \n",
       "284786  0.588482  0.632444 -0.201064  0.199251  0.438657  0.172923    8.95   \n",
       "284787  0.293632  0.107812 -0.935586  1.138216  0.025271  0.255347    9.99   \n",
       "284788  0.416765  0.064819 -0.608337  0.268436 -0.028069 -0.041367    3.99   \n",
       "284789 -0.148093 -0.038712  0.010209 -0.362666  0.503092  0.229921   60.50   \n",
       "284790  0.300245  0.000607 -0.376379  0.128660 -0.015205 -0.021486    9.81   \n",
       "284791 -0.074513 -0.003988 -0.113149  0.280378 -0.077310  0.023079   20.32   \n",
       "284792 -0.059545  0.242669 -0.665424 -0.269869 -0.170579 -0.030692    3.99   \n",
       "284793  0.163002  0.726365 -0.058282 -0.191813  0.061858 -0.043716    4.99   \n",
       "284794  0.088485 -0.076790 -0.095833  0.132720 -0.028468  0.126494    0.89   \n",
       "284795  0.890675 -1.253276  1.786717  0.320763  2.090712  1.232864    9.87   \n",
       "284796 -0.042114 -0.053206  0.316403 -0.461441  0.018265 -0.041068   60.00   \n",
       "284797  0.279598  0.371441 -0.559238  0.113144  0.131507  0.081265    5.49   \n",
       "284798  0.251791  0.057688 -1.508368  0.144023  0.181205  0.215243   24.05   \n",
       "284799 -0.348929  0.745323  0.704545 -0.127579  0.454379  0.130308   79.99   \n",
       "284800  0.297930 -0.359769 -0.315610  0.201114 -0.080826 -0.075071    2.68   \n",
       "284801  0.050343  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "12          0  \n",
       "13          0  \n",
       "14          0  \n",
       "15          0  \n",
       "16          0  \n",
       "17          0  \n",
       "18          0  \n",
       "19          0  \n",
       "20          0  \n",
       "21          0  \n",
       "22          0  \n",
       "23          0  \n",
       "24          0  \n",
       "25          0  \n",
       "26          0  \n",
       "27          0  \n",
       "28          0  \n",
       "29          0  \n",
       "...       ...  \n",
       "284777      0  \n",
       "284778      0  \n",
       "284779      0  \n",
       "284780      0  \n",
       "284781      0  \n",
       "284782      0  \n",
       "284783      0  \n",
       "284784      0  \n",
       "284785      0  \n",
       "284786      0  \n",
       "284787      0  \n",
       "284788      0  \n",
       "284789      0  \n",
       "284790      0  \n",
       "284791      0  \n",
       "284792      0  \n",
       "284793      0  \n",
       "284794      0  \n",
       "284795      0  \n",
       "284796      0  \n",
       "284797      0  \n",
       "284798      0  \n",
       "284799      0  \n",
       "284800      0  \n",
       "284801      0  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in data\n",
    "credit = pd.read_csv('creditcard.csv')\n",
    "credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Highly imbalanced class prediction, shows need for class balancing \n",
    "sns.countplot('Class', data=credit)\n",
    "plt.title('Class Distributions', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit.loc[:, credit.columns != 'Class']\n",
    "y = credit.loc[:, credit.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the majority and minority Class.\n",
    "class_majority = credit[credit.Class==0]\n",
    "class_minority = credit[credit.Class==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use downsample of the minority class to address the class imbalance. \n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Downsample majority class sample without replacement to match minority class\n",
    "credit_maj_downsampled = resample(class_majority, replace=False,n_samples=len(class_minority))    \n",
    "                                \n",
    "# Combine minority class with downsampled majority class\n",
    "credit_downsampled = pd.concat([credit_maj_downsampled, class_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.9086294416243654\n",
      "Testing on Sample: 0.9054878048780488\n",
      "[0.93       0.94       0.95918367 0.86734694 0.87755102 0.84693878\n",
      " 0.96938776 0.8877551  0.89795918 0.85714286]\n",
      "Native Bayes Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       101\n",
      "           1       1.00      0.81      0.90        96\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       197\n",
      "   macro avg       0.92      0.91      0.91       197\n",
      "weighted avg       0.92      0.91      0.91       197\n",
      "\n",
      "AUC: 0.948\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Native Bayes \n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "# Instantiate our model and Fit our model to the data.\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_subsample, Y_subsample)\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(bnb, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "#Classification report \n",
    "from sklearn.metrics import classification_report\n",
    "print('Native Bayes Classification report :')\n",
    "print(classification_report(y_test, bnb.predict(X_test)))\n",
    "\n",
    "#AUC \n",
    "probs = bnb.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 7 candidates, totalling 49 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 2}\n",
      "0.4258130081300813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    9.7s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Model 2: KNN gridsearch\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# Initialize the model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Set parameters for KNN\n",
    "# List of values to try \n",
    "knn_params = [{'n_neighbors': [2,3,5,7,10,15,25]}]\n",
    "\n",
    "#GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, \n",
    "    #n_jobs=None, iid=’warn’, refit=True, cv=’warn’, verbose=0, pre_dispatch=‘2*n_jobs’,\n",
    "    #error_score=’raise-deprecating’, return_train_score=’warn’)\n",
    "\n",
    "# Search for the best paramters. \n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=7, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid and obtain results\n",
    "knn_grid.fit(X_subsample, Y_subsample)\n",
    "\n",
    "# Return best parameters and best score\n",
    "print(knn_grid.best_params_)\n",
    "print(knn_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.6598984771573604\n",
      "Testing on Sample: 0.8404471544715447\n",
      "[0.45       0.44       0.41836735 0.42857143 0.41836735 0.43877551\n",
      " 0.70408163 0.47959184 0.48979592 0.43877551]\n",
      "KNN report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       101\n",
      "           1       1.00      0.65      0.78        96\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       197\n",
      "   macro avg       0.87      0.82      0.82       197\n",
      "weighted avg       0.87      0.83      0.82       197\n",
      "\n",
      "AUC: 0.930\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nearest neighbors model \n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "knn.fit(X,Y)\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(knn.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(knn.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(knn, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('KNN report :')\n",
    "print(classification_report(y_test, knn.predict(X_test)))\n",
    "\n",
    "#AUC \n",
    "probs = knn.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  9.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 8, 'n_estimators': 15}\n",
      "0.9359756097560976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed: 10.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Random Forest gridsearchcv  \n",
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [15, 200, 500, 750, 1000, 1500],\n",
    "    'max_features': [1,2,4,6,7,8],\n",
    "    'max_depth': [4,5,6,7,8]\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(rfc, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_subsample, Y_subsample)\n",
    "\n",
    "# Show the best parameter and best score for unfiltered\n",
    "print(grid.best_params_)\n",
    "print( grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.9187817258883249\n",
      "Testing on Sample: 0.9573170731707317\n",
      "[0.95       0.98       0.97959184 0.87755102 0.90816327 0.93877551\n",
      " 0.96938776 0.89795918 0.94897959 0.89795918]\n",
      "Random Forest report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       101\n",
      "           1       0.98      0.88      0.92        96\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       197\n",
      "   macro avg       0.93      0.93      0.93       197\n",
      "weighted avg       0.93      0.93      0.93       197\n",
      "\n",
      "AUC: 0.988\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random forest model \n",
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier(n_estimators=15, max_features=8, max_depth=4)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(rfc.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(rfc.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(rfc, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Random Forest report :')\n",
    "print(classification_report(y_test, rfc.predict(X_test)))\n",
    "\n",
    "\n",
    "#AUC \n",
    "probs = rfc.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'penalty': 'l1'}\n",
      "0.9288617886178862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression Gridsearch cv \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logr = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = (0.0001,0.001, 0.01, 0.1, 1)\n",
    "\n",
    "# Create hyperparameter options\n",
    "parameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Use GS-CV to see which alpha level is best.\n",
    "\n",
    "logr_grid = GridSearchCV(logr, parameters, cv=5, verbose=1)\n",
    "\n",
    "#Fit the logistic regression \n",
    "logr_grid.fit(X_subsample, Y_subsample)\n",
    "\n",
    "#return best parameters and best score\n",
    "\n",
    "print(logr_grid.best_params_)\n",
    "print(logr_grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.9238578680203046\n",
      "Testing on Sample: 0.9451219512195121\n",
      "[0.96       0.99       0.96938776 0.87755102 0.8877551  0.96938776\n",
      " 0.94897959 0.90816327 0.96938776 0.87755102]\n",
      "Logistic regression report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       101\n",
      "           1       0.96      0.89      0.92        96\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       197\n",
      "   macro avg       0.93      0.92      0.92       197\n",
      "weighted avg       0.93      0.92      0.92       197\n",
      "\n",
      "AUC: 0.978\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic regression model \n",
    "logr = LogisticRegression(C=.1, penalty='l1')\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "logr.fit(X,Y)\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(logr.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(logr.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(logr, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Logistic regression report :')\n",
    "print(classification_report(y_test, logr.predict(X_test)))\n",
    "\n",
    "#AUC \n",
    "probs = logr.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 28 candidates, totalling 196 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-06, 'gamma': 0.001}\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 196 out of 196 | elapsed:    6.4s finished\n"
     ]
    }
   ],
   "source": [
    "# SVM gridsearch best parameters \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "# new parameters for this model\n",
    "svc_params = [{'C': [.000001,.00001,.001,.01,.1,1,10], 'gamma': [.0001,.001,.01,.1]}]\n",
    "\n",
    "# setting up the grid\n",
    "svc_grid = GridSearchCV(svm, svc_params, cv=7, verbose=1, n_jobs=-1)\n",
    "\n",
    "#Fit the grid\n",
    "svc_grid.fit(X_subsample, Y_subsample)\n",
    "\n",
    "#return best parameters and best score\n",
    "\n",
    "print(svc_grid.best_params_)\n",
    "print(svc_grid.best_score_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.4873096446700508\n",
      "Testing on Sample: 0.6097560975609756\n",
      "[0.5        0.5        0.5        0.5        0.5        0.5\n",
      " 0.5        0.48979592 0.5        0.5       ]\n",
      "SVM report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       101\n",
      "           1       1.00      0.23      0.37        96\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       197\n",
      "   macro avg       0.79      0.61      0.55       197\n",
      "weighted avg       0.78      0.62      0.56       197\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when  probability=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-7084772fca71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# calculate AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \"\"\"\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             raise AttributeError(\"predict_proba is not available when \"\n\u001b[0m\u001b[1;32m    586\u001b[0m                                  \" probability=False\")\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'c_svc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nu_svc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict_proba is not available when  probability=False"
     ]
    }
   ],
   "source": [
    "# SVM model \n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=1e-06, gamma=.001)\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "svm.fit(X,Y)\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(svm.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(svm.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(svm, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('SVM report :')\n",
    "print(classification_report(y_test, svm.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 63 candidates, totalling 315 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 315 out of 315 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'n_estimators': 100}\n",
      "0.9308943089430894\n"
     ]
    }
   ],
   "source": [
    "# Parameters to test in gridsearch cv \n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "params = {'n_estimators': [50, 100, 150, 200, 300, 500, 700, 1000, 1500],\n",
    "          'max_depth': [2,3,4,5,6,7,8],\n",
    "         }\n",
    "\n",
    "# Initialize and fit the model.\n",
    "gb = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "# Use the grid\n",
    "gb_grid = GridSearchCV(gb, params, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid\n",
    "gb_grid.fit(X_subsample, Y_subsample)\n",
    "\n",
    "# Return best parameters and best score\n",
    "print(gb_grid.best_params_)\n",
    "print(gb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.9035532994923858\n",
      "Testing on Sample: 1.0\n",
      "[0.94       0.99       0.96938776 0.8877551  0.8877551  0.94897959\n",
      " 0.93877551 0.92857143 0.93877551 0.8877551 ]\n",
      "Gradient Boosting report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       101\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       197\n",
      "   macro avg       1.00      1.00      1.00       197\n",
      "weighted avg       1.00      1.00      1.00       197\n",
      "\n",
      "AUC: 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient boosting model \n",
    "# Best Parameters from gridsearchcv \n",
    "params = {'n_estimators': 100,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "gb = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "gb.fit(X,Y)\n",
    "\n",
    "\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(gb.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(gb, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Gradient Boosting report :')\n",
    "print(classification_report(y_test, gb.predict(X_test)))\n",
    "\n",
    "#AUC \n",
    "probs = gb.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 6}\n",
      "0.9247967479674797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Gridsearch \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "# Initialize the model\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "# Set parameters for dtc\n",
    "params = [{'max_features': [2, 4, 6, 8],\n",
    "             'max_depth': [2, 4, 6, 8]}]\n",
    "\n",
    "# Search for the best paramters. \n",
    "decision_tree_grid = GridSearchCV(decision_tree, params, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid and obtain results\n",
    "decision_tree_grid.fit(X_subsample, Y_subsample)\n",
    "\n",
    "# Return best parameters and best score\n",
    "print(decision_tree_grid.best_params_)\n",
    "print(decision_tree_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.8984771573604061\n",
      "Testing on Sample: 0.9451219512195121\n",
      "AUC: 0.966\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94       0.96       0.94897959 0.85714286 0.82653061 0.90816327\n",
      " 0.96938776 0.85714286 0.87755102 0.86734694]\n",
      "Decision Tree report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       101\n",
      "           1       0.98      0.85      0.91        96\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       197\n",
      "   macro avg       0.93      0.92      0.92       197\n",
      "weighted avg       0.92      0.92      0.92       197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "decision_tree = DecisionTreeClassifier( \n",
    "    criterion='entropy',\n",
    "    max_features=6,\n",
    "    max_depth=4)\n",
    "\n",
    "X_subsample = credit_downsampled.loc[:, credit_downsampled.columns != 'Class']\n",
    "Y_subsample = credit_downsampled['Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subsample,Y_subsample, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(decision_tree.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(decision_tree.fit(X_subsample, Y_subsample).score(X_subsample, Y_subsample)))\n",
    "\n",
    "\n",
    "# Cross validating using 10 folds  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(decision_tree, X_subsample, Y_subsample, cv=10))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print('Decision Tree report :')\n",
    "print(classification_report(y_test, decision_tree.predict(X_test)))\n",
    "\n",
    "#AUC \n",
    "probs = decision_tree.predict_proba(X_test)\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at the classification report and determining the best performing model, the precision and recall are particularly important. The precision is the ability of the classifier not to label as positive a sample that is negative. The recall is the ability of the classifier to find all the positive samples. Additionally, the\n",
    "\n",
    "The lowest performing models were the SVM classifier and the Gradient boosted classfiier. The SVM produced test results below 60% on testing sets and at around 60% on the test sets and simply cannot be used. I was surprised by the performance of the gradient booted, I think it was subject to overfittng by producing a perfect test score and showing “perfect skill” in the AUC plot. For this reason, this model also cannot be used.  \n",
    "\n",
    "The remaining models performed well, with the best being the Random Forest Classifier and the logisitic regression model a close second. The Random Forest classifier had the highest scoring precision value and AUC of 0.988. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In performing analysis on this dataset, the main challenge I encountered was the imbalanced class variable. I overcame this challenge by using sckit learn resample to downsample and create a balanced subset of data where the number of fraudulent cases matched the number of non-fradulent cases. This step was important as it helped prevent intense overfitting of my model. In all, the random forest classifier was the best performing model and the model that should be used in fraud detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
