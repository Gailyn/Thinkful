{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New final capstone.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzbZVy8RoVTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from sklearn import ensemble\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from sklearn.utils import resample\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "import warnings\n",
        "# filter warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "# Import various componenets for model building\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import LSTM, Input, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# Import the backend\n",
        "from keras import backend as K\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "import glob\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDpVMMOdqbnR",
        "colab_type": "text"
      },
      "source": [
        "Objective: build a model predicting users’ demographic characteristics based on their app usage, geolocation, and cell phone properties. Furthermore, the goal is to aid developers and marketers engage in data-driven efforts that are relevant to and personalized to their end users preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm60-O4KqaAH",
        "colab_type": "text"
      },
      "source": [
        "# Processing the data\n",
        "\n",
        "In this first section I will read in the Talkingdata using the Kaggle API in addtion to preparing the data to be visualized and modeled "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLLwe-CWod8a",
        "colab_type": "code",
        "outputId": "5f3e8410-5595-4280-be99-570422d7d204",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a50ea7d-039c-4b57-a90c-cd2aa6036293\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3a50ea7d-039c-4b57-a90c-cd2aa6036293\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"gailyn\",\"key\":\"f838642402b2c5fc90e6d2d0e8d7b171\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaS8soWcok40",
        "colab_type": "code",
        "outputId": "3d61b719-ee7d-404d-ab29-7c9c4243ea62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls -lha kaggle.json"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 62 Nov 22 18:03 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV-myHP4onKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdtuFgYJoqyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so moving it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r5kCUCpotW4",
        "colab_type": "code",
        "outputId": "ac943bd9-c4b0-48a8-f1be-beff31356da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "!kaggle competitions download -c talkingdata-mobile-user-demographics"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading gender_age_test.csv.zip to /content\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\n",
            "\r100% 1.05M/1.05M [00:00<00:00, 73.0MB/s]\n",
            "Downloading app_labels.csv.zip to /content\n",
            "\r  0% 0.00/4.04M [00:00<?, ?B/s]\n",
            "\r100% 4.04M/4.04M [00:00<00:00, 37.2MB/s]\n",
            "Downloading label_categories.csv.zip to /content\n",
            "\r  0% 0.00/7.67k [00:00<?, ?B/s]\n",
            "\r100% 7.67k/7.67k [00:00<00:00, 6.78MB/s]\n",
            "Downloading phone_brand_device_model.csv.zip to /content\n",
            "\r  0% 0.00/2.42M [00:00<?, ?B/s]\n",
            "\r100% 2.42M/2.42M [00:00<00:00, 165MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "\r  0% 0.00/1.32M [00:00<?, ?B/s]\n",
            "\r100% 1.32M/1.32M [00:00<00:00, 189MB/s]\n",
            "Downloading events.csv.zip to /content\n",
            "\r  0% 0.00/62.2M [00:00<?, ?B/s]\r  8% 5.00M/62.2M [00:00<00:02, 22.7MB/s]\r 14% 9.00M/62.2M [00:00<00:02, 24.6MB/s]\r 40% 25.0M/62.2M [00:00<00:01, 28.7MB/s]\r 53% 33.0M/62.2M [00:00<00:00, 34.7MB/s]\r 92% 57.0M/62.2M [00:01<00:00, 38.7MB/s]\n",
            "100% 62.2M/62.2M [00:01<00:00, 47.7MB/s]\n",
            "Downloading app_events.csv.zip to /content\n",
            " 99% 210M/211M [00:03<00:00, 60.6MB/s]\n",
            "100% 211M/211M [00:03<00:00, 62.0MB/s]\n",
            "Downloading gender_age_train.csv.zip to /content\n",
            "  0% 0.00/891k [00:00<?, ?B/s]\n",
            "100% 891k/891k [00:00<00:00, 124MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ9iUWH2ouG8",
        "colab_type": "code",
        "outputId": "32bfc565-01dc-4d96-f75e-bbb6484cd767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!ls \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " app_events.csv.zip\t    kaggle.json\n",
            " app_labels.csv.zip\t    label_categories.csv.zip\n",
            " events.csv.zip\t\t    phone_brand_device_model.csv.zip\n",
            " gender_age_test.csv.zip    sample_data\n",
            " gender_age_train.csv.zip   sample_submission.csv.zip\n",
            "'kaggle (1).json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZG_K8e2oysn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzipping all of the files to gain acess to csv for each subset \n",
        "with zipfile.ZipFile('app_events.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('app_events.csv')\n",
        "\n",
        "with zipfile.ZipFile('app_labels.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('app_labels.csv')\n",
        "\n",
        "with zipfile.ZipFile('events.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('events.csv')\n",
        "\n",
        "with zipfile.ZipFile('gender_age_test.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('gender_age_test.csv')\n",
        "\n",
        "with zipfile.ZipFile('gender_age_train.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('gender_age_train.csv')\n",
        "\n",
        "with zipfile.ZipFile('label_categories.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('label_categories.csv')\n",
        "\n",
        "with zipfile.ZipFile('phone_brand_device_model.csv.zip', 'r') as zip_ref:\n",
        "  zip_ref.extractall('phone_brand_device_model.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDnp-uF1o7A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apps = pd.read_csv(('app_events.csv/app_events.csv'),usecols=['event_id','app_id','is_active'], dtype={'is_active':bool})\n",
        "\n",
        "gendertest = pd.read_csv('gender_age_test.csv/gender_age_test.csv')\n",
        "gendertrain = pd.read_csv(('gender_age_train.csv/gender_age_train.csv'),index_col='device_id')\n",
        "\n",
        "phone = pd.read_csv('phone_brand_device_model.csv/phone_brand_device_model.csv')\n",
        "# Get rid of duplicate device ids in phone\n",
        "phone = phone.drop_duplicates('device_id',keep='first')\n",
        "\n",
        "app_labels = pd.read_csv('app_labels.csv/app_labels.csv')\n",
        "events = pd.read_csv(('events.csv/events.csv'), usecols = ['event_id', 'device_id'])\n",
        "labelcats = pd.read_csv(('label_categories.csv/label_categories.csv'),index_col='label_id',squeeze=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRP-X5vXqCAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isHBdktBqGqS",
        "colab_type": "text"
      },
      "source": [
        "# Exploration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er3rdZOnqJAK",
        "colab_type": "code",
        "outputId": "2cd91e68-7d1a-4be4-f551-041c3bd1c676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "gendertrain"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>device_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-8076087639492063270</th>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-2897161552818060146</th>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-8260683887967679142</th>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-4938849341048082022</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>M29-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245133531816851882</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>M29-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4682031842235089751</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>M29-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-9178703742877135986</th>\n",
              "      <td>M</td>\n",
              "      <td>30</td>\n",
              "      <td>M29-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180946546684162312</th>\n",
              "      <td>M</td>\n",
              "      <td>20</td>\n",
              "      <td>M22-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1390702386071991851</th>\n",
              "      <td>M</td>\n",
              "      <td>37</td>\n",
              "      <td>M32-38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89181010588227347</th>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>M23-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74645 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     gender  age   group\n",
              "device_id                               \n",
              "-8076087639492063270      M   35  M32-38\n",
              "-2897161552818060146      M   35  M32-38\n",
              "-8260683887967679142      M   35  M32-38\n",
              "-4938849341048082022      M   30  M29-31\n",
              " 245133531816851882       M   30  M29-31\n",
              "...                     ...  ...     ...\n",
              " 4682031842235089751      M   30  M29-31\n",
              "-9178703742877135986      M   30  M29-31\n",
              " 180946546684162312       M   20    M22-\n",
              " 1390702386071991851      M   37  M32-38\n",
              " 89181010588227347        M   25  M23-26\n",
              "\n",
              "[74645 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1bhc_jDtdhL",
        "colab_type": "code",
        "outputId": "8c0045ee-d29a-4dec-8a39-b670bedc6325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "gendertest"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002079943728939269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1547860181818787117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7374582448058474277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-6220210354783429585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5893464122623104785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112066</th>\n",
              "      <td>4280900819321920929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112067</th>\n",
              "      <td>818534825520551359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112068</th>\n",
              "      <td>-8956851351560395765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112069</th>\n",
              "      <td>6097318236795836256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112070</th>\n",
              "      <td>622421180514002079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>112071 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  device_id\n",
              "0       1002079943728939269\n",
              "1      -1547860181818787117\n",
              "2       7374582448058474277\n",
              "3      -6220210354783429585\n",
              "4      -5893464122623104785\n",
              "...                     ...\n",
              "112066  4280900819321920929\n",
              "112067   818534825520551359\n",
              "112068 -8956851351560395765\n",
              "112069  6097318236795836256\n",
              "112070   622421180514002079\n",
              "\n",
              "[112071 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFWXSMX4tor5",
        "colab_type": "code",
        "outputId": "3c18430c-8f9f-443b-d15a-96d738a3fafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "apps"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>5927333115845830913</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-5720078949152207372</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>-1633887856876571208</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>-653184325010919369</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>8693964245073640147</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32473062</th>\n",
              "      <td>3252948</td>\n",
              "      <td>6607018907660377991</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32473063</th>\n",
              "      <td>3252948</td>\n",
              "      <td>6602285879264922467</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32473064</th>\n",
              "      <td>3252948</td>\n",
              "      <td>4348659952760821294</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32473065</th>\n",
              "      <td>3252948</td>\n",
              "      <td>-995726944612374565</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32473066</th>\n",
              "      <td>3252948</td>\n",
              "      <td>2306067392090419925</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32473067 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          event_id               app_id  is_active\n",
              "0                2  5927333115845830913       True\n",
              "1                2 -5720078949152207372      False\n",
              "2                2 -1633887856876571208      False\n",
              "3                2  -653184325010919369       True\n",
              "4                2  8693964245073640147       True\n",
              "...            ...                  ...        ...\n",
              "32473062   3252948  6607018907660377991       True\n",
              "32473063   3252948  6602285879264922467       True\n",
              "32473064   3252948  4348659952760821294       True\n",
              "32473065   3252948  -995726944612374565       True\n",
              "32473066   3252948  2306067392090419925       True\n",
              "\n",
              "[32473067 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xc3fA3gGts0-",
        "colab_type": "code",
        "outputId": "99315144-9fa6-4623-c6fd-c891ac74a1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "phone"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>phone_brand</th>\n",
              "      <th>device_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8890648629457979026</td>\n",
              "      <td>小米</td>\n",
              "      <td>红米</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1277779817574759137</td>\n",
              "      <td>小米</td>\n",
              "      <td>MI 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5137427614288105724</td>\n",
              "      <td>三星</td>\n",
              "      <td>Galaxy S4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3669464369358936369</td>\n",
              "      <td>SUGAR</td>\n",
              "      <td>时尚手机</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5019277647504317457</td>\n",
              "      <td>三星</td>\n",
              "      <td>Galaxy Note 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187239</th>\n",
              "      <td>3210973037848940984</td>\n",
              "      <td>小米</td>\n",
              "      <td>MI 2S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187240</th>\n",
              "      <td>7979541072208733273</td>\n",
              "      <td>小米</td>\n",
              "      <td>MI 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187241</th>\n",
              "      <td>-187404680852357705</td>\n",
              "      <td>小米</td>\n",
              "      <td>红米2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187242</th>\n",
              "      <td>-2718274279595622821</td>\n",
              "      <td>小米</td>\n",
              "      <td>MI 3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187243</th>\n",
              "      <td>3098391762071677791</td>\n",
              "      <td>vivo</td>\n",
              "      <td>X1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>186716 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  device_id phone_brand   device_model\n",
              "0      -8890648629457979026          小米             红米\n",
              "1       1277779817574759137          小米           MI 2\n",
              "2       5137427614288105724          三星      Galaxy S4\n",
              "3       3669464369358936369       SUGAR           时尚手机\n",
              "4      -5019277647504317457          三星  Galaxy Note 2\n",
              "...                     ...         ...            ...\n",
              "187239  3210973037848940984          小米          MI 2S\n",
              "187240  7979541072208733273          小米           MI 4\n",
              "187241  -187404680852357705          小米            红米2\n",
              "187242 -2718274279595622821          小米           MI 3\n",
              "187243  3098391762071677791        vivo             X1\n",
              "\n",
              "[186716 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoyD0GLKtwJN",
        "colab_type": "code",
        "outputId": "a3358ca4-51cf-412b-baca-1f40d9347b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "app_labels.info()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 459943 entries, 0 to 459942\n",
            "Data columns (total 2 columns):\n",
            "app_id      459943 non-null int64\n",
            "label_id    459943 non-null int64\n",
            "dtypes: int64(2)\n",
            "memory usage: 7.0 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1TUVF9pt1py",
        "colab_type": "code",
        "outputId": "08526459-683e-4559-bcfc-08ff8731ee72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "labelcats"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label_id\n",
              "1                       NaN\n",
              "2            game-game type\n",
              "3          game-Game themes\n",
              "4            game-Art Style\n",
              "5         game-Leisure time\n",
              "               ...         \n",
              "1017    Heritage Foundation\n",
              "1018         Direct Banking\n",
              "1019    Internet Securities\n",
              "1020       Bank Credit Card\n",
              "1021     Internet Insurance\n",
              "Name: category, Length: 930, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ5ZK1c0ugLk",
        "colab_type": "text"
      },
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfMeaQmbuoVq",
        "colab_type": "text"
      },
      "source": [
        "## Age"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2iIq183utNt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> The age of the users skews towards the younger side with the most active users being in their 20s, despite the average age represented is 31\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eBMBtpst1UR",
        "colab_type": "code",
        "outputId": "68c1bb04-4cb4-4ffe-a4cd-84f7a8ac51f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "gendertrain.describe()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>74645.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>31.410342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.868735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>29.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>36.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                age\n",
              "count  74645.000000\n",
              "mean      31.410342\n",
              "std        9.868735\n",
              "min        1.000000\n",
              "25%       25.000000\n",
              "50%       29.000000\n",
              "75%       36.000000\n",
              "max       96.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lI0fwKSvAa4",
        "colab_type": "code",
        "outputId": "767b8864-b15f-4da3-dfd8-2656cb594c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(gendertrain.age.mode())\n",
        "print(gendertrain.age.min())\n",
        "print(gendertrain.age.max())\n",
        "print(gendertrain.age.median())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    26\n",
            "dtype: int64\n",
            "1\n",
            "96\n",
            "29.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QboNb1zvHDx",
        "colab_type": "code",
        "outputId": "03a793e3-e0d8-4a62-e856-62de7d243a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.title('Age Distribution')\n",
        "#genderTrain.gender\n",
        "sns.distplot(gendertrain.age)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f89fd883588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyx/JjaDGBQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zZtqE_lvWU3",
        "colab_type": "text"
      },
      "source": [
        "## Gender"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1Evdga5vbpK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> The dataset has a heavy empahsis on male users. When looking at category distribution, the most heavily populated categories are males 23 to 38. Overall when compaing in respective age groups the male users outnumber the female users.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e63kGs4wIps",
        "colab_type": "code",
        "outputId": "d847a601-b30c-4b38-e0f2-b5f1163fce56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "gendertrain.gender.value_counts().plot(kind='barh')\n",
        "plt.title('Gender Distribution')\n",
        "plt.xlabel('Count')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZ0z6CWpc/8PtH/SemAxit8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx07oWCfwSJ8",
        "colab_type": "code",
        "outputId": "e0ddb090-44ff-49f2-d86a-399543f0d819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "gendertrain.group.value_counts().plot(kind='barh')\n",
        "plt.title('Group Distribution')\n",
        "plt.xlabel('Individuals')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Individuals')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEWCAYAAABFSLFOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXd4XaX6wc6j",
        "colab_type": "text"
      },
      "source": [
        "## App Usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjvwaRjQwYX4",
        "colab_type": "code",
        "outputId": "a38ebebd-38a7-43cd-e783-bcaa7ae25dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "apps.is_active.value_counts().plot(kind='barh')\n",
        "plt.title('Active usage versus inactive usage')\n",
        "plt.xlabel('Count')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Count')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n372Ru+8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcsmKNEiqRT7",
        "colab_type": "text"
      },
      "source": [
        "# Merging the subsets of the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBEAyKhJqdYx",
        "colab_type": "code",
        "outputId": "669e2ca0-d97b-4547-c730-4c23d9203b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "app_merge = pd.read_csv('app_events.csv/app_events.csv', usecols=['event_id','app_id','is_active'])\n",
        "device_b = (\n",
        "    app_merge\n",
        "    \n",
        "     # Merge on event_id\n",
        "    .merge(events, how = 'left', left_on = 'event_id', right_on = 'event_id')\n",
        "    \n",
        "     # event_id itself is not interesting\n",
        "    .drop('event_id', axis = 1)\n",
        "    \n",
        "     # Because the events correspond to more than just\n",
        "     # being installed, there are many duplicates\n",
        "    .drop_duplicates()\n",
        ")\n",
        "\n",
        "# Our data now looks like this\n",
        "device_b.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>device_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5927333115845830913</td>\n",
              "      <td>1</td>\n",
              "      <td>-6401643145415154744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5720078949152207372</td>\n",
              "      <td>0</td>\n",
              "      <td>-6401643145415154744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1633887856876571208</td>\n",
              "      <td>0</td>\n",
              "      <td>-6401643145415154744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-653184325010919369</td>\n",
              "      <td>1</td>\n",
              "      <td>-6401643145415154744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8693964245073640147</td>\n",
              "      <td>1</td>\n",
              "      <td>-6401643145415154744</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                app_id  is_active            device_id\n",
              "0  5927333115845830913          1 -6401643145415154744\n",
              "1 -5720078949152207372          0 -6401643145415154744\n",
              "2 -1633887856876571208          0 -6401643145415154744\n",
              "3  -653184325010919369          1 -6401643145415154744\n",
              "4  8693964245073640147          1 -6401643145415154744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdhXc3svqljy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine the two columns\n",
        "phone['brand_and_model'] = phone['phone_brand'].astype(str) + phone['device_model']\n",
        "\n",
        "# Build numerical labels for our models\n",
        "model_encoder = LabelEncoder().fit(phone['brand_and_model'])\n",
        "\n",
        "# Store in a new column\n",
        "phone['encoded_model'] = model_encoder.transform(phone['brand_and_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu4oXt_wruQQ",
        "colab_type": "code",
        "outputId": "70a87e55-c8d9-4fdc-e8ba-2397597ccbf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "events.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_id</th>\n",
              "      <th>device_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>29182687948017175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-6401643145415154744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>-4833982096941402721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>-6815121365017318426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>-5373797595892518570</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   event_id            device_id\n",
              "0         1    29182687948017175\n",
              "1         2 -6401643145415154744\n",
              "2         3 -4833982096941402721\n",
              "3         4 -6815121365017318426\n",
              "4         5 -5373797595892518570"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta2wgU9srbOd",
        "colab_type": "code",
        "outputId": "1869dbf2-c6d0-4c92-91f2-922629f22669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        " # Adding labels to app_events\n",
        "apps_labeled = pd.merge(app_labels,\n",
        "                       apps[['app_id', 'is_active']],\n",
        "                       on='app_id').dropna().drop_duplicates()\n",
        "\n",
        "print(apps_labeled.shape)\n",
        "apps_labeled.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(117374, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>app_id</th>\n",
              "      <th>label_id</th>\n",
              "      <th>is_active</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7324884708820027918</td>\n",
              "      <td>251</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7324884708820027918</td>\n",
              "      <td>251</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7324884708820027918</td>\n",
              "      <td>691</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7324884708820027918</td>\n",
              "      <td>691</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7324884708820027918</td>\n",
              "      <td>751</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 app_id  label_id  is_active\n",
              "0   7324884708820027918       251      False\n",
              "6   7324884708820027918       251       True\n",
              "11  7324884708820027918       691      False\n",
              "17  7324884708820027918       691       True\n",
              "22  7324884708820027918       751      False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP4P5Ibp1_N9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFGMrp7XsqMb",
        "colab_type": "code",
        "outputId": "e6826610-d69d-49af-c676-868fe071689e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Merge gendertrain and device_b\n",
        "gt_device = pd.merge(gendertrain,\n",
        "                  device_b[['app_id', 'is_active', 'device_id']],\n",
        "                  on='device_id').dropna().drop_duplicates()\n",
        "#Shape of ga_apps\n",
        "print(gt_device.shape)\n",
        "\n",
        "# Show how the new df looks.\n",
        "gt_device.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1097150, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>-4085686983594738208</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>6324194957022958681</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>-8687507491028761317</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>877288515501232570</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id gender  age   group               app_id  is_active\n",
              "0 -8260683887967679142      M   35  M32-38  4287147352639325907          0\n",
              "1 -8260683887967679142      M   35  M32-38 -4085686983594738208          0\n",
              "2 -8260683887967679142      M   35  M32-38  6324194957022958681          0\n",
              "3 -8260683887967679142      M   35  M32-38 -8687507491028761317          0\n",
              "4 -8260683887967679142      M   35  M32-38   877288515501232570          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lht4xnLstva",
        "colab_type": "code",
        "outputId": "64688adb-6dbf-42ac-c17f-ec81f021e1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "# Merge the previous data set with brands now. \n",
        "gt_phoneapps = pd.merge(gt_device,\n",
        "                         phone[['device_id', 'encoded_model']],\n",
        "                         on='device_id').dropna().drop_duplicates()\n",
        "\n",
        "print(gt_phoneapps.shape)\n",
        "\n",
        "#Look at how the data looks.\n",
        "gt_phoneapps.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1097150, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>encoded_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>-4085686983594738208</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>6324194957022958681</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>-8687507491028761317</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>877288515501232570</td>\n",
              "      <td>1</td>\n",
              "      <td>843</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id gender  ...  is_active encoded_model\n",
              "0 -8260683887967679142      M  ...          0           843\n",
              "1 -8260683887967679142      M  ...          0           843\n",
              "2 -8260683887967679142      M  ...          0           843\n",
              "3 -8260683887967679142      M  ...          0           843\n",
              "4 -8260683887967679142      M  ...          1           843\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onNUzDyss4Zz",
        "colab_type": "code",
        "outputId": "1817184e-a2a2-40ba-ee90-093124ee8eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "\n",
        "# Putting all of the data sets together.\n",
        "gender_full = pd.merge(gt_phoneapps,\n",
        "                                 apps_labeled[['app_id', 'label_id']],\n",
        "                                 on='app_id').dropna().drop_duplicates()\n",
        "\n",
        "print(gender_full.shape)\n",
        "\n",
        "#Look at how the data looks.\n",
        "gender_full.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7034111, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>encoded_model</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>M</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8761770737926125955</td>\n",
              "      <td>F</td>\n",
              "      <td>22</td>\n",
              "      <td>F23-</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8761770737926125955</td>\n",
              "      <td>F</td>\n",
              "      <td>22</td>\n",
              "      <td>F23-</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id gender  age  ... is_active  encoded_model  label_id\n",
              "0 -8260683887967679142      M   35  ...         0            843       713\n",
              "2 -8260683887967679142      M   35  ...         0            843       704\n",
              "4 -8260683887967679142      M   35  ...         0            843       548\n",
              "6  8761770737926125955      F   22  ...         0            226       713\n",
              "8  8761770737926125955      F   22  ...         0            226       704\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C4QVgJetOau",
        "colab_type": "code",
        "outputId": "6ffdad0c-cef2-4d85-be3e-c5ae1709a695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# feature engineering\n",
        "# Convert gender into a binary output\n",
        "gender_full['gender'] = gender_full['gender'].apply(lambda x: 1 if x == 'M' else 0 )\n",
        "gender_full.gender.value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4942458\n",
              "0    2091653\n",
              "Name: gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88VEo_XgtVuO",
        "colab_type": "code",
        "outputId": "11edaf85-266b-4d72-d5ef-cf92294c5d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "\n",
        "# Make another copy since the previous copy has already been dummified.\n",
        "# Putting all of the data sets together.\n",
        "gender_full_copy = pd.merge(gt_phoneapps,\n",
        "                                 apps_labeled[['app_id', 'label_id']],\n",
        "                                 on='app_id').dropna().drop_duplicates()\n",
        "\n",
        "# Convert gender into a binary output\n",
        "gender_full_copy ['gender'] = gender_full_copy['gender'].apply(lambda x: 1 if x == 'M' else 0 )\n",
        "\n",
        "#Show me the shape\n",
        "print(gender_full_copy.shape)\n",
        "\n",
        "#Look at how the data looks.\n",
        "gender_full_copy.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7034111, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>encoded_model</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8761770737926125955</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>F23-</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8761770737926125955</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>F23-</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id  gender  age  ... is_active  encoded_model  label_id\n",
              "0 -8260683887967679142       1   35  ...         0            843       713\n",
              "2 -8260683887967679142       1   35  ...         0            843       704\n",
              "4 -8260683887967679142       1   35  ...         0            843       548\n",
              "6  8761770737926125955       0   22  ...         0            226       713\n",
              "8  8761770737926125955       0   22  ...         0            226       704\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5A43ZBlteQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFIQGq6Oty0Y",
        "colab_type": "code",
        "outputId": "6a68e0bb-da8e-4300-b8e7-56d6277c0179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "\n",
        "# Convert label_id into a continuous variable\n",
        "# even though it's numerical, it hasn't been standardized \n",
        "type_dummies = pd.get_dummies(gender_full['label_id'])\n",
        "\n",
        "# Concatenate the dummies with the original data set.\n",
        "gender_full = pd.concat([gender_full, type_dummies], axis=1)\n",
        "\n",
        "print(gender_full.shape)\n",
        "\n",
        "gender_full.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7034111, 493)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>encoded_model</th>\n",
              "      <th>label_id</th>\n",
              "      <th>2</th>\n",
              "      <th>4</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>973</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>980</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>993</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "      <th>1002</th>\n",
              "      <th>1003</th>\n",
              "      <th>1005</th>\n",
              "      <th>1006</th>\n",
              "      <th>1007</th>\n",
              "      <th>1008</th>\n",
              "      <th>1009</th>\n",
              "      <th>1010</th>\n",
              "      <th>1011</th>\n",
              "      <th>1012</th>\n",
              "      <th>1013</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>713</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>704</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-8260683887967679142</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>M32-38</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>843</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8761770737926125955</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>F23-</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>713</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8761770737926125955</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>F23-</td>\n",
              "      <td>4287147352639325907</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>704</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 493 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             device_id  gender  age   group  ...  1018  1019  1020  1021\n",
              "0 -8260683887967679142       1   35  M32-38  ...     0     0     0     0\n",
              "2 -8260683887967679142       1   35  M32-38  ...     0     0     0     0\n",
              "4 -8260683887967679142       1   35  M32-38  ...     0     0     0     0\n",
              "6  8761770737926125955       0   22    F23-  ...     0     0     0     0\n",
              "8  8761770737926125955       0   22    F23-  ...     0     0     0     0\n",
              "\n",
              "[5 rows x 493 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY-toZB4t16g",
        "colab_type": "code",
        "outputId": "9fe66a2f-3a7a-4903-cdec-a03c7d3cc598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "source": [
        "gender_full.group.value_counts()\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M32-38    1185421\n",
              "M39+      1107632\n",
              "M23-26     817660\n",
              "M29-31     810956\n",
              "M27-28     530780\n",
              "F33-42     517420\n",
              "M22-       490009\n",
              "F43+       391188\n",
              "F29-32     368450\n",
              "F23-       303034\n",
              "F24-26     265262\n",
              "F27-28     246299\n",
              "Name: group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfxbJdCO59hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downsampling the gender/age training set to 50000.\n",
        "#ga_m_youngest = ga_apps_labeled_brands[ga_apps_labeled_brands.group=='M22-']\n",
        "cat1=gender_full[gender_full.group=='M22-']\n",
        "cat1_downsampled = resample(cat1,replace=True,n_samples=30000)\n",
        "cat2= gender_full[gender_full.group=='M23-26']\n",
        "cat2_downsampled = resample(cat2,replace=True,n_samples=30000)\n",
        "cat3 = gender_full[gender_full.group=='M27-28']\n",
        "cat3_downsampled = resample(cat3, replace=True, n_samples=30000) \n",
        "\n",
        "cat4 = gender_full[gender_full.group=='M29-31']\n",
        "cat4_downsampled = resample(cat4,replace=True, n_samples=30000)\n",
        "cat5 = gender_full[gender_full.group=='M32-38']\n",
        "cat5_downsampled = resample(cat5, replace=True,  n_samples=30000)\n",
        "\n",
        "cat6 = gender_full[gender_full.group=='M39+']\n",
        "cat6_downsampled = resample(cat6, replace=True, n_samples=30000)\n",
        "\n",
        "# Downsample majority class\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcOhndLeWcXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cat7 = gender_full[gender_full.group=='F23-']\n",
        "cat7_downsampled = resample(cat7, replace=True, n_samples=30000)\n",
        "\n",
        "cat8 = gender_full[gender_full.group=='F24-26']\n",
        "cat8_downsampled = resample(cat8, replace=True, n_samples=30000)\n",
        "\n",
        "cat9 = gender_full[gender_full.group=='F27-28']\n",
        "cat9_downsampled = resample(cat9, replace=True, n_samples=30000)\n",
        "cat10 = gender_full[gender_full.group=='F29-32']\n",
        "cat10_downsampled = resample(cat10, replace=True, n_samples=30000)\n",
        "cat11 = gender_full[gender_full.group=='F33-42']\n",
        "cat11_downsampled = resample(cat11, replace=True,n_samples=30000)\n",
        "cat12 = gender_full[gender_full.group=='F43+']\n",
        "cat12_downsampled = resample(cat12, replace=True, n_samples=30000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXaQOa4EWeXc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "77eee115-b261-4ae9-e3f7-0d439ce7741b"
      },
      "source": [
        "\n",
        "# Combine downsampled majority class \n",
        "gender_full_sampled = pd.concat([cat1_downsampled,cat2_downsampled,\n",
        "                               cat3_downsampled,cat4_downsampled,\n",
        "                               cat5_downsampled, cat6_downsampled,\n",
        "                               cat7_downsampled, cat8_downsampled,\n",
        "                               cat9_downsampled, cat10_downsampled,\n",
        "                              cat11_downsampled, cat12_downsampled])\n",
        " \n",
        "# Display new class counts\n",
        "gender_full_sampled.group.value_counts()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "M29-31    30000\n",
              "F23-      30000\n",
              "F27-28    30000\n",
              "M23-26    30000\n",
              "M22-      30000\n",
              "F29-32    30000\n",
              "F24-26    30000\n",
              "M27-28    30000\n",
              "F33-42    30000\n",
              "M39+      30000\n",
              "F43+      30000\n",
              "M32-38    30000\n",
              "Name: group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbQbA5iGNWBx",
        "colab_type": "text"
      },
      "source": [
        "# Using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqbVp1V9QHiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA \n",
        "# PCA for 10 components \n",
        "from sklearn.decomposition import PCA\n",
        "X = gender_full_sampled.drop(['group'], axis=1)\n",
        "y = gender_full_sampled['group'].values\n",
        "\n",
        "# Use PCA to create new columns \n",
        "pca = PCA(n_components=10)\n",
        "principalComponents = pca.fit_transform(X)\n",
        "pca_X = pd.DataFrame(data = principalComponents, \n",
        "                     columns = ['principal component 1', 'principal component 2', 'principal component 3', \n",
        "                                'principal component 4','principal component 5','principal component 6', \n",
        "                               'principal component 7', 'principal component 8','principal component 9','principal component 10'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpEmJgnsSpos",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgWwOvRXSovN",
        "colab_type": "code",
        "outputId": "11a3d08e-b530-422e-d4f6-d1c6bb16cda8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Instantiate our model and Fit our model to the data.\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(pca_X, y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.3, random_state=200)\n",
        "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(bnb.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(bnb,pca_X , y, cv=10))\n",
        "\n",
        "#Classification report \n",
        "from sklearn.metrics import classification_report\n",
        "print('Native Bayes Classification report :')\n",
        "print(classification_report(y_test, bnb.predict(X_test)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.3544888888888889\n",
            "Testing on Sample: 0.3542533333333333\n",
            "[0.3504     0.3532     0.353      0.35773333 0.35246667 0.3532\n",
            " 0.35133333 0.35653333 0.35276667 0.35376667]\n",
            "Native Bayes Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       0.30      0.38      0.33      7397\n",
            "      F24-26       0.29      0.25      0.26      7514\n",
            "      F27-28       0.27      0.46      0.34      7405\n",
            "      F29-32       0.00      0.00      0.00      7628\n",
            "      F33-42       0.49      0.49      0.49      7603\n",
            "        F43+       0.47      0.59      0.53      7425\n",
            "        M22-       0.27      0.34      0.30      7505\n",
            "      M23-26       0.27      0.15      0.19      7499\n",
            "      M27-28       0.26      0.50      0.34      7621\n",
            "      M29-31       0.27      0.05      0.09      7466\n",
            "      M32-38       0.51      0.55      0.53      7529\n",
            "        M39+       0.52      0.51      0.51      7408\n",
            "\n",
            "    accuracy                           0.35     90000\n",
            "   macro avg       0.33      0.35      0.33     90000\n",
            "weighted avg       0.33      0.35      0.33     90000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtecXt4sSuOP",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56HvSfteTEiZ",
        "colab_type": "code",
        "outputId": "5539fc5a-0770-465e-d4b6-3c71268a8398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Model 3: Random Forest gridsearchcv  took 300 min \n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "\n",
        "\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [15, 200, 500],\n",
        "    'max_features': [7,8,9,10],\n",
        "    'max_depth': [6,7,8]\n",
        "}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(rfc, param_grid, cv=2, verbose=3, n_jobs=-1)\n",
        "\n",
        "grid.fit(pca_X,y)\n",
        "\n",
        "# Show the best parameter and best score \n",
        "print(grid.best_params_)\n",
        "print( grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 23.7min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 94.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 8, 'max_features': 8, 'n_estimators': 15}\n",
            "0.9924533333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFmQFWfnUmWf",
        "colab_type": "code",
        "outputId": "f85c55c9-6c5d-4cb3-a0e2-437d07e177b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "# Random forest model using pca , \n",
        "from sklearn import ensemble\n",
        "rfc = ensemble.RandomForestClassifier(n_estimators=15, max_features= 8, max_depth=8)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X, y ,test_size=0.2, random_state=100)\n",
        "print('With 20% Holdout: ' + str(rfc.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(rfc.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(rfc, pca_X, y, cv=10))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Random Forest report :')\n",
        "print(classification_report(y_test, rfc.predict(X_test)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9893833333333333\n",
            "Testing on Sample: 0.9913766666666667\n",
            "[0.9909     0.99023333 0.99256667 0.9897     0.99026667 0.99236667\n",
            " 0.99196667 0.99056667 0.9912     0.99276667]\n",
            "Random Forest report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      0.99      1.00      4910\n",
            "      F24-26       0.97      0.99      0.98      5058\n",
            "      F27-28       0.97      0.97      0.97      4908\n",
            "      F29-32       1.00      0.98      0.99      4981\n",
            "      F33-42       1.00      1.00      1.00      5079\n",
            "        F43+       1.00      1.00      1.00      5034\n",
            "        M22-       1.00      1.00      1.00      5000\n",
            "      M23-26       1.00      0.99      0.99      5073\n",
            "      M27-28       0.98      1.00      0.99      4986\n",
            "      M29-31       0.99      0.99      0.99      4937\n",
            "      M32-38       1.00      1.00      1.00      5055\n",
            "        M39+       1.00      1.00      1.00      4979\n",
            "\n",
            "    accuracy                           0.99     60000\n",
            "   macro avg       0.99      0.99      0.99     60000\n",
            "weighted avg       0.99      0.99      0.99     60000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBazfqY7VQvH",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQslOD4pVP-9",
        "colab_type": "code",
        "outputId": "7964861b-67b1-48b8-fadd-4c6aaa4ee3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Decision Tree Gridsearch \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Set parameters for dtc\n",
        "params = [{'max_features': [7, 8, 9, 10],\n",
        "             'max_depth': [ 6, 7,8]}]\n",
        "\n",
        "\n",
        "\n",
        "# Search for the best paramters. \n",
        "decision_tree_grid = GridSearchCV(decision_tree, params, cv=2, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid and obtain results\n",
        "decision_tree_grid.fit(pca_X, y)\n",
        "\n",
        "# Return best parameters and best score\n",
        "print(decision_tree_grid.best_params_)\n",
        "print(decision_tree_grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   17.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 8, 'max_features': 10}\n",
            "0.9871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Cwe05zVZEU",
        "colab_type": "code",
        "outputId": "6d414d1c-9642-4839-f8d6-76ea1c665085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "decision_tree = DecisionTreeClassifier( \n",
        "    criterion='entropy',\n",
        "    max_features=10,\n",
        "    max_depth=8)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(decision_tree.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(decision_tree.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(decision_tree, pca_X, y, cv=10))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Decision Tree report :')\n",
        "print(classification_report(y_test, decision_tree.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9982\n",
            "Testing on Sample: 0.9977133333333333\n",
            "[0.9976     0.9969     0.9977     0.9984     0.99776667 0.99736667\n",
            " 0.99856667 0.99766667 0.99726667 0.99773333]\n",
            "Decision Tree report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      4988\n",
            "      F24-26       0.99      1.00      0.99      4944\n",
            "      F27-28       1.00      0.98      0.99      4900\n",
            "      F29-32       0.99      1.00      1.00      4962\n",
            "      F33-42       1.00      1.00      1.00      4973\n",
            "        F43+       1.00      1.00      1.00      5041\n",
            "        M22-       1.00      1.00      1.00      5022\n",
            "      M23-26       1.00      1.00      1.00      5104\n",
            "      M27-28       1.00      1.00      1.00      4970\n",
            "      M29-31       1.00      1.00      1.00      5044\n",
            "      M32-38       1.00      1.00      1.00      5037\n",
            "        M39+       1.00      1.00      1.00      5015\n",
            "\n",
            "    accuracy                           1.00     60000\n",
            "   macro avg       1.00      1.00      1.00     60000\n",
            "weighted avg       1.00      1.00      1.00     60000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYo0MMnU8NO",
        "colab_type": "text"
      },
      "source": [
        "###Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16362vHdyPUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up best parameters\n",
        "lr3 = LogisticRegression(C=100, max_iter=25, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Fit the model\n",
        "lr3.fit(X_train2, y_train2)\n",
        "\n",
        "lr3.score(X_train2, y_train2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcnVVUwAx4dj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXe9qfQVvCr-",
        "colab_type": "code",
        "outputId": "e0e98f83-b117-4bf9-c489-a12f728b35bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Set up best parameters\n",
        "lr3 = LogisticRegression(C=1, max_iter=5, multi_class='multinomial', solver='lbfgs')\n",
        "\n",
        "# Fit the model\n",
        "lr3.fit(pca_X, y)\n",
        "\n",
        "lr3.score(pca_X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BWeinJnVES7",
        "colab_type": "code",
        "outputId": "328bb979-928c-4b9f-83d3-eb4e411aabdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Logistic Regression Gridsearch cv \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logr = LogisticRegression()\n",
        "\n",
        "# Create regularization penalty space\n",
        "penalty = ['l1', 'l2']\n",
        "\n",
        "# Create regularization hyperparameter space\n",
        "C = (0.01, 0.1, 1, 10, 100, 1000)\n",
        "\n",
        "# Create hyperparameter options\n",
        "parameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "# Use GS-CV to see which alpha level is best.\n",
        "\n",
        "logr_grid = GridSearchCV(logr, parameters, cv=2, verbose=1)\n",
        "\n",
        "#Fit the logistic regression \n",
        "logr_grid.fit(pca_X, y)\n",
        "\n",
        "#return best parameters and best score\n",
        "\n",
        "print(logr_grid.best_params_)\n",
        "print(logr_grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_AURnhhVXCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic regression model \n",
        "logr = LogisticRegression(C= 10, penalty='l1')\n",
        "\n",
        "\n",
        "logr.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X, y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(logr.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(logr.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(logr, pca_X, y, cv=3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Logistic regression report :')\n",
        "print(classification_report(y_test, logr.predict(X_test)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF7wD-UbqCbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic regression model \n",
        "logr = LogisticRegression(C= 10, penalty='l1')\n",
        "\n",
        "\n",
        "logr.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X, y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(logr.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(logr.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(logr, pca_X, y, cv=10))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Logistic regression report :')\n",
        "print(classification_report(y_test, logr.predict(X_test)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOoxyWYtUiVm",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Boosting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXsZyYDGUhj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters to test in gridsearch cv \n",
        "\n",
        "params = {'n_estimators': [150, 200, 300, 500],\n",
        "                           \n",
        "          'max_depth': [5,6,7,8],\n",
        "         }\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier()\n",
        "\n",
        "# Use the grid\n",
        "gb_grid = GridSearchCV(gb, params, cv=2, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid\n",
        "gb_grid.fit(pca_X, y)\n",
        "\n",
        "# Return best parameters and best score\n",
        "print(gb_grid.best_params_)\n",
        "print(gb_grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2QH6dbUVBPN",
        "colab_type": "code",
        "outputId": "67d09fdd-6e0c-4474-c38a-39b869695d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 50,\n",
        "          'max_depth': 6,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, pca_X, y, cv=2))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9995416666666667\n",
            "Testing on Sample: 1.0\n",
            "[0.9995     0.99948889]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5965\n",
            "      F24-26       1.00      1.00      1.00      5851\n",
            "      F27-28       1.00      1.00      1.00      5995\n",
            "      F29-32       1.00      1.00      1.00      6045\n",
            "      F33-42       1.00      1.00      1.00      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       1.00      1.00      1.00      6132\n",
            "      M23-26       1.00      1.00      1.00      6006\n",
            "      M27-28       1.00      1.00      1.00      6011\n",
            "      M29-31       1.00      1.00      1.00      6004\n",
            "      M32-38       1.00      1.00      1.00      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           1.00     72000\n",
            "   macro avg       1.00      1.00      1.00     72000\n",
            "weighted avg       1.00      1.00      1.00     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5RhBJlw-6W7",
        "colab_type": "code",
        "outputId": "7d86ea63-2479-4657-eaf1-15ef76443936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 25,\n",
        "          'max_depth': 4,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, pca_X, y, cv=2))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9911111111111112\n",
            "Testing on Sample: 0.9914222222222222\n",
            "[0.98869444 0.98929444]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       0.99      1.00      1.00      5965\n",
            "      F24-26       0.98      0.99      0.99      5851\n",
            "      F27-28       1.00      0.98      0.99      5995\n",
            "      F29-32       0.99      0.99      0.99      6045\n",
            "      F33-42       1.00      1.00      1.00      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       0.99      1.00      1.00      6132\n",
            "      M23-26       0.98      0.98      0.98      6006\n",
            "      M27-28       0.98      0.97      0.98      6011\n",
            "      M29-31       0.99      0.99      0.99      6004\n",
            "      M32-38       0.99      0.99      0.99      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           0.99     72000\n",
            "   macro avg       0.99      0.99      0.99     72000\n",
            "weighted avg       0.99      0.99      0.99     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68oCYeSEyRym",
        "colab_type": "code",
        "outputId": "38ddf6b8-637a-4885-e7f7-1c7273dfb5ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 10,\n",
        "          'max_depth': 4,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, pca_X, y, cv=3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9401388888888889\n",
            "Testing on Sample: 0.9408222222222222\n",
            "[0.94481111 0.93969444]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       0.99      1.00      0.99      5965\n",
            "      F24-26       0.93      0.91      0.92      5851\n",
            "      F27-28       0.87      0.82      0.84      5995\n",
            "      F29-32       0.87      0.92      0.89      6045\n",
            "      F33-42       0.95      0.98      0.97      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       0.99      1.00      1.00      6132\n",
            "      M23-26       0.97      0.94      0.96      6006\n",
            "      M27-28       0.90      0.87      0.88      6011\n",
            "      M29-31       0.87      0.89      0.88      6004\n",
            "      M32-38       0.94      0.97      0.96      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           0.94     72000\n",
            "   macro avg       0.94      0.94      0.94     72000\n",
            "weighted avg       0.94      0.94      0.94     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dTkY42F0YQB",
        "colab_type": "code",
        "outputId": "f867eb4a-00b6-403e-b813-1cc129f3122f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 5,\n",
        "          'max_depth': 8,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, pca_X, y, cv=3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9994583333333333\n",
            "Testing on Sample: 0.9999666666666667\n",
            "[0.9993     0.99929167 0.999325  ]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5965\n",
            "      F24-26       1.00      1.00      1.00      5851\n",
            "      F27-28       1.00      1.00      1.00      5995\n",
            "      F29-32       1.00      1.00      1.00      6045\n",
            "      F33-42       1.00      1.00      1.00      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       1.00      1.00      1.00      6132\n",
            "      M23-26       1.00      1.00      1.00      6006\n",
            "      M27-28       1.00      1.00      1.00      6011\n",
            "      M29-31       1.00      1.00      1.00      6004\n",
            "      M32-38       1.00      1.00      1.00      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           1.00     72000\n",
            "   macro avg       1.00      1.00      1.00     72000\n",
            "weighted avg       1.00      1.00      1.00     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlDBwVIl9xiA",
        "colab_type": "code",
        "outputId": "a66ec74b-2856-4b73-ff9d-b1dbe7b7fcea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 5,\n",
        "          'max_depth': 4,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, pca_X, y, cv=3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9386944444444445\n",
            "Testing on Sample: 0.9395083333333333\n",
            "[0.94098333 0.938275   0.93901667]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       0.99      1.00      0.99      5965\n",
            "      F24-26       0.93      0.90      0.92      5851\n",
            "      F27-28       0.87      0.81      0.84      5995\n",
            "      F29-32       0.87      0.92      0.89      6045\n",
            "      F33-42       0.95      0.98      0.97      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       0.99      1.00      0.99      6132\n",
            "      M23-26       0.97      0.93      0.95      6006\n",
            "      M27-28       0.89      0.87      0.88      6011\n",
            "      M29-31       0.87      0.89      0.88      6004\n",
            "      M32-38       0.94      0.97      0.96      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           0.94     72000\n",
            "   macro avg       0.94      0.94      0.94     72000\n",
            "weighted avg       0.94      0.94      0.94     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsMtaTazUnfC",
        "colab_type": "text"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ8WwhMQUrGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# SVM model using features \n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(C=.1, gamma=.01)\n",
        "\n",
        "\n",
        "# AttributeError: predict_proba is not available when  probability=False -> ERROR FOR SVM AUC \n",
        "\n",
        "\n",
        "svm.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(svm.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(svm.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(svm, pca_X,y, cv=5))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('SVM report :')\n",
        "print(classification_report(y_test, svm.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J8alGOi_Xzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM model using features \n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(C=.1, gamma=.01)\n",
        "\n",
        "\n",
        "# AttributeError: predict_proba is not available when  probability=False -> ERROR FOR SVM AUC \n",
        "\n",
        "\n",
        "svm.fit(pca_X,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(svm.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(svm.fit(pca_X, y).score(pca_X, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(svm, pca_X,y, cv=5))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('SVM report :')\n",
        "print(classification_report(y_test, svm.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAGjhTx2NZPA",
        "colab_type": "text"
      },
      "source": [
        "# Supervised methods uUsing Selectk Best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fueo89GNa1w",
        "colab_type": "code",
        "outputId": "ad354f54-6254-463b-fc18-32996460451c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "\n",
        "# selectKbest \n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "X = gender_full_sampled.drop(['group'], axis=1)\n",
        "y = gender_full_sampled['group'].values\n",
        "\n",
        "# Perform feature selection\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "selector.fit(X,y)\n",
        "\n",
        "X_new = selector.transform(X)\n",
        "X_new.shape\n",
        "print(selector.get_support(indices=True))\n",
        "\n",
        "# Most 10  useful cols \n",
        "X_new = selector.transform(X)\n",
        "print(X_new.shape)\n",
        "# Col names \n",
        "X.columns[selector.get_support(indices=True)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  1   2   4   5   6 174 276 445 446 477]\n",
            "(360000, 10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([       'gender',           'age',     'is_active', 'encoded_model',\n",
              "            'label_id',             209,             706,             959,\n",
              "                   960,            1007],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06z2cEUJWRGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating data frame with our choosen features \n",
        "features = gender_full_sampled[['gender', 'age','is_active', 'encoded_model','label_id', 706,730, 959, 960,1007]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7_ZiQm1AtSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za9uQ2fDAeNu",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGslqAFgAg70",
        "colab_type": "code",
        "outputId": "072a1cd3-8ea1-4432-bb89-03951c22febb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Model 3: Random Forest gridsearchcv  took 300 min \n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rfc = ensemble.RandomForestClassifier()\n",
        "\n",
        "\n",
        "\n",
        "param_grid = { \n",
        "    'n_estimators': [15, 200, 500],\n",
        "    'max_features': [7,8,9,10],\n",
        "    'max_depth': [6,7,8]\n",
        "}\n",
        "\n",
        "\n",
        "grid = GridSearchCV(rfc, param_grid, cv=2, verbose=3, n_jobs=-1)\n",
        "\n",
        "grid.fit(features,y)\n",
        "\n",
        "# Show the best parameter and best score \n",
        "print(grid.best_params_)\n",
        "print( grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 11.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 6, 'max_features': 7, 'n_estimators': 15}\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSeZtJklGvzC",
        "colab_type": "code",
        "outputId": "021b9c6e-a503-43ad-ee05-b76165cd4551",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Random forest model using selectk best , \n",
        "from sklearn import ensemble\n",
        "rfc = ensemble.RandomForestClassifier(n_estimators=15, max_features= 7, max_depth=6)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, y ,test_size=0.2, random_state=100)\n",
        "print('With 20% Holdout: ' + str(rfc.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(rfc.fit(features, y).score(features, y)))\n",
        "\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(rfc, features, y, cv=5))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Random Forest report :')\n",
        "print(classification_report(y_test, rfc.predict(X_test)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 1.0\n",
            "Testing on Sample: 1.0\n",
            "[1. 1. 1. 1. 1.]\n",
            "Random Forest report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5932\n",
            "      F24-26       1.00      1.00      1.00      6082\n",
            "      F27-28       1.00      1.00      1.00      5975\n",
            "      F29-32       1.00      1.00      1.00      6026\n",
            "      F33-42       1.00      1.00      1.00      5917\n",
            "        F43+       1.00      1.00      1.00      6023\n",
            "        M22-       1.00      1.00      1.00      5913\n",
            "      M23-26       1.00      1.00      1.00      6134\n",
            "      M27-28       1.00      1.00      1.00      5897\n",
            "      M29-31       1.00      1.00      1.00      6066\n",
            "      M32-38       1.00      1.00      1.00      6014\n",
            "        M39+       1.00      1.00      1.00      6021\n",
            "\n",
            "    accuracy                           1.00     72000\n",
            "   macro avg       1.00      1.00      1.00     72000\n",
            "weighted avg       1.00      1.00      1.00     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ-NKqWixOLM",
        "colab_type": "code",
        "outputId": "23398008-96d4-446d-9994-f1578a2cb94d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Random forest model using selectk best , \n",
        "from sklearn import ensemble\n",
        "rfc = ensemble.RandomForestClassifier(n_estimators=10, max_features= 5, max_depth=4)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, y ,test_size=0.2, random_state=100)\n",
        "print('With 20% Holdout: ' + str(rfc.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(rfc.fit(features, y).score(features, y)))\n",
        "\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(rfc, features, y, cv=5))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Random Forest report :')\n",
        "print(classification_report(y_test, rfc.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9318333333333333\n",
            "Testing on Sample: 1.0\n",
            "[0.999375   1.         0.93513889 1.         0.99591667]\n",
            "Random Forest report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5932\n",
            "      F24-26       1.00      1.00      1.00      6082\n",
            "      F27-28       1.00      1.00      1.00      5975\n",
            "      F29-32       1.00      1.00      1.00      6026\n",
            "      F33-42       1.00      1.00      1.00      5917\n",
            "        F43+       1.00      1.00      1.00      6023\n",
            "        M22-       1.00      1.00      1.00      5913\n",
            "      M23-26       1.00      1.00      1.00      6134\n",
            "      M27-28       1.00      1.00      1.00      5897\n",
            "      M29-31       1.00      1.00      1.00      6066\n",
            "      M32-38       1.00      1.00      1.00      6014\n",
            "        M39+       1.00      1.00      1.00      6021\n",
            "\n",
            "    accuracy                           1.00     72000\n",
            "   macro avg       1.00      1.00      1.00     72000\n",
            "weighted avg       1.00      1.00      1.00     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT0_8loFxgtF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqOtaPRKxhV8",
        "colab_type": "code",
        "outputId": "b77a62e7-f66f-483e-e665-99e5093fe1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Decision Tree Gridsearch \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "\n",
        "# Set parameters for dtc\n",
        "params = [{'max_features': [7, 8, 9, 10],\n",
        "             'max_depth': [ 6, 7,8]}]\n",
        "\n",
        "\n",
        "\n",
        "# Search for the best paramters. \n",
        "decision_tree_grid = GridSearchCV(decision_tree, params, cv=2, verbose=1, n_jobs=-1)\n",
        "\n",
        "# Fit the grid and obtain results\n",
        "decision_tree_grid.fit(features, y)\n",
        "\n",
        "# Return best parameters and best score\n",
        "print(decision_tree_grid.best_params_)\n",
        "print(decision_tree_grid.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    8.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 6, 'max_features': 9}\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6INGqK5EygLW",
        "colab_type": "code",
        "outputId": "1037e26a-5acb-4875-fbea-f1ae45dfc3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "decision_tree = DecisionTreeClassifier( \n",
        "    criterion='entropy',\n",
        "    max_features=6,\n",
        "    max_depth=8)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(decision_tree.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(decision_tree.fit(features, y).score(features, y)))\n",
        "\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(decision_tree, features, y, cv=5))\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Decision Tree report :')\n",
        "print(classification_report(y_test, decision_tree.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.9786666666666667\n",
            "Testing on Sample: 0.9465527777777778\n",
            "[0.97311111 0.93401389 0.99597222 0.98234722 0.88301389]\n",
            "Decision Tree report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5965\n",
            "      F24-26       1.00      1.00      1.00      5851\n",
            "      F27-28       1.00      1.00      1.00      5995\n",
            "      F29-32       1.00      1.00      1.00      6045\n",
            "      F33-42       1.00      1.00      1.00      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       1.00      1.00      1.00      6132\n",
            "      M23-26       1.00      1.00      1.00      6006\n",
            "      M27-28       1.00      1.00      1.00      6011\n",
            "      M29-31       0.64      1.00      0.78      6004\n",
            "      M32-38       0.84      0.47      0.60      6001\n",
            "        M39+       1.00      0.88      0.94      6075\n",
            "\n",
            "    accuracy                           0.95     72000\n",
            "   macro avg       0.96      0.95      0.94     72000\n",
            "weighted avg       0.96      0.95      0.94     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDqYLV43zjyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7daaoaXVzkiy",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cihwnftfzIdJ",
        "colab_type": "code",
        "outputId": "b4bc5715-5734-40bd-9c19-8f03b2c54cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Instantiate our model and Fit our model to the data.\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(features, y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,y, test_size=0.3, random_state=200)\n",
        "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(bnb.fit(features, y).score(features, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(bnb,features , y, cv=5))\n",
        "\n",
        "#Classification report \n",
        "from sklearn.metrics import classification_report\n",
        "print('Native Bayes Classification report :')\n",
        "print(classification_report(y_test, bnb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 0.18021296296296296\n",
            "Testing on Sample: 0.18036666666666668\n",
            "[0.17997222 0.17854167 0.18       0.18129167 0.18119444]\n",
            "Native Bayes Classification report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       0.17      0.67      0.28      9031\n",
            "      F24-26       0.18      0.32      0.23      9085\n",
            "      F27-28       0.00      0.00      0.00      8971\n",
            "      F29-32       0.00      0.00      0.00      9016\n",
            "      F33-42       0.21      0.04      0.06      9024\n",
            "        F43+       0.30      0.05      0.09      8974\n",
            "        M22-       0.17      0.72      0.28      8896\n",
            "      M23-26       0.00      0.00      0.00      9054\n",
            "      M27-28       0.00      0.00      0.00      9133\n",
            "      M29-31       0.19      0.03      0.05      8965\n",
            "      M32-38       0.00      0.00      0.00      9005\n",
            "        M39+       0.19      0.34      0.24      8846\n",
            "\n",
            "    accuracy                           0.18    108000\n",
            "   macro avg       0.12      0.18      0.10    108000\n",
            "weighted avg       0.12      0.18      0.10    108000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko1eSBdAz5wc",
        "colab_type": "code",
        "outputId": "65da46c2-697e-4a36-8efa-c231a49ca164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 5,\n",
        "          'max_depth': 8,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(features,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(features, y).score(features, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, features, y, cv=3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 1.0\n",
            "Testing on Sample: 1.0\n",
            "[1. 1. 1.]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5965\n",
            "      F24-26       1.00      1.00      1.00      5851\n",
            "      F27-28       1.00      1.00      1.00      5995\n",
            "      F29-32       1.00      1.00      1.00      6045\n",
            "      F33-42       1.00      1.00      1.00      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       1.00      1.00      1.00      6132\n",
            "      M23-26       1.00      1.00      1.00      6006\n",
            "      M27-28       1.00      1.00      1.00      6011\n",
            "      M29-31       1.00      1.00      1.00      6004\n",
            "      M32-38       1.00      1.00      1.00      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           1.00     72000\n",
            "   macro avg       1.00      1.00      1.00     72000\n",
            "weighted avg       1.00      1.00      1.00     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urMUOykK0SF2",
        "colab_type": "code",
        "outputId": "a78f746f-7840-4454-b7f5-93e8b6d9dffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "# Gradient boosting model \n",
        "# Best Parameters from gridsearchcv \n",
        "params = {'n_estimators': 5,\n",
        "          'max_depth': 4,\n",
        "          'loss': 'deviance'}\n",
        "\n",
        "# Initialize and fit the model.\n",
        "gb = ensemble.GradientBoostingClassifier(**params)\n",
        "\n",
        "gb.fit(features,y)\n",
        "\n",
        "# Use train_test_split to create the necessary training and test groups\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,y, test_size=0.2, random_state=20)\n",
        "print('With 20% Holdout: ' + str(gb.fit(X_train, y_train).score(X_test, y_test)))\n",
        "print('Testing on Sample: ' + str(gb.fit(features, y).score(features, y)))\n",
        "\n",
        "# Cross validating using 10 folds  \n",
        "from sklearn.model_selection import cross_val_score\n",
        "print(cross_val_score(gb, features, y, cv=3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Gradient Boosting report :')\n",
        "print(classification_report(y_test, gb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With 20% Holdout: 1.0\n",
            "Testing on Sample: 1.0\n",
            "[1. 1. 1.]\n",
            "Gradient Boosting report :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        F23-       1.00      1.00      1.00      5965\n",
            "      F24-26       1.00      1.00      1.00      5851\n",
            "      F27-28       1.00      1.00      1.00      5995\n",
            "      F29-32       1.00      1.00      1.00      6045\n",
            "      F33-42       1.00      1.00      1.00      5936\n",
            "        F43+       1.00      1.00      1.00      5979\n",
            "        M22-       1.00      1.00      1.00      6132\n",
            "      M23-26       1.00      1.00      1.00      6006\n",
            "      M27-28       1.00      1.00      1.00      6011\n",
            "      M29-31       1.00      1.00      1.00      6004\n",
            "      M32-38       1.00      1.00      1.00      6001\n",
            "        M39+       1.00      1.00      1.00      6075\n",
            "\n",
            "    accuracy                           1.00     72000\n",
            "   macro avg       1.00      1.00      1.00     72000\n",
            "weighted avg       1.00      1.00      1.00     72000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Ef7f4S54JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t27lwDsp55ee",
        "colab_type": "text"
      },
      "source": [
        "# Unsupervised Learning Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y26UqNwF9vJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create X and y \n",
        "X = gender_full_sampled.drop(['group'], axis=1)\n",
        "Y = gender_full_sampled['group'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s_uBj3d58YC",
        "colab_type": "code",
        "outputId": "50015b88-0020-40b0-d53b-78b4edaefd52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create X and y \n",
        "X = gender_full_sampled.drop(['group'], axis=1)\n",
        "Y = gender_full_sampled['group'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=0)\n",
        "\n",
        "#fitting the model with 12 clusters for 12 groups \n",
        "kmeans_pred = KMeans(n_clusters=12, random_state=42).fit_predict(X_train)\n",
        "\n",
        "#Print cross tab of data vs prediction\n",
        "print('Comparing K-Means Clusters to Demographics:')\n",
        "print(pd.crosstab(y_train, kmeans_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing K-Means Clusters to Authors:\n",
            "col_0     0     1     2     3     4     5     6     7     8     9     10    11\n",
            "row_0                                                                         \n",
            "F23-    1847  1802  1646  1672  2368  1769  1733  1400  1731  2456  2403  1508\n",
            "F24-26  1594  1928  1573  1714  2818  1668  1503  1508  1892  2464  2419  1571\n",
            "F27-28  1651  1698  1676  1769  2330  1563  1760  1781  1662  2537  2320  1765\n",
            "F29-32  1708  1776  1606  1870  2417  1877  1557  1580  1670  2321  2467  1585\n",
            "F33-42  1612  1717  1788  1713  2300  1812  1723  1777  1671  2270  2372  1718\n",
            "F43+    1646  2108  1892  1637  2512  1599  1728  1670  1806  1977  2102  2006\n",
            "M22-    1888  1816  1682  1612  2491  1633  1647  1447  1972  2328  2389  1616\n",
            "M23-26  1887  1731  1702  1736  2349  1669  1679  1533  1821  2457  2357  1513\n",
            "M27-28  1844  1583  1739  1827  2257  1644  1599  1384  1875  2631  2539  1551\n",
            "M29-31  1712  1657  1795  1795  2288  1650  1794  1543  1783  2522  2349  1633\n",
            "M32-38  1727  1706  1799  1885  2263  1708  1792  1448  1778  2491  2259  1618\n",
            "M39+    1920  1769  1734  1705  2295  1923  1687  1368  1783  2186  2477  1641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMGxU4tb8SXl",
        "colab_type": "code",
        "outputId": "52e87220-fa5f-4582-c3a9-6520aff2277b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "#Show authors categorized by cluster\n",
        "p_y = pd.crosstab(kmeans_pred, y_train)\n",
        "p_y.plot(kind='bar', stacked=False, figsize=[20,5])\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJgAAAE/CAYAAAAKdXlBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okH7M6XPXY-L",
        "colab_type": "code",
        "outputId": "ca2febac-b97a-49f8-fd73-84170b050f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "model = KMeans(n_clusters=12, random_state=42).fit_predict(X_train)\n",
        "\n",
        "\n",
        "print(metrics.silhouette_score(X_train, model, metric='euclidean'))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.37761587941482705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ynZNAR1GMl35",
        "colab": {}
      },
      "source": [
        "#Declare and fit the model.\n",
        "\n",
        "# need to make smaller due to crashing and using all of ram \n",
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create X and y \n",
        "X = gender_full_sampled.drop(['group'], axis=1)\n",
        "Y = gender_full_sampled['group'].values\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.25,\n",
        "                                                    random_state=0)\n",
        "spectral_pred = SpectralClustering(n_clusters=12).fit_predict(X_train)\n",
        "\n",
        "#Print cross tab of data vs prediction\n",
        "print('Comparing Spectral Clusters to Demographic Groups:')\n",
        "print(pd.crosstab(y_train, spectral_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCYE6JkNFMUl",
        "colab_type": "code",
        "outputId": "726f8ebb-4ac9-4311-ba7a-16e4b5b904e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "#Show authors categorized by cluster\n",
        "prediction = pd.crosstab(spectral_pred, y_train)\n",
        "prediction.plot(kind='bar', stacked=False, figsize=[20,5])\n",
        "plt.title('Demographic Groups Categorized by Spectral Clusters')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAFPCAYAAAAMSQTHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiQV8Q1H3ZxTZwDbIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LA5jiaIFXBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwUZKGinG0NC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCcZfvMFG07i",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoIzcuAqG4fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "# Import various componenets for model building\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, MaxoutDense\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.optimizers import RMSprop, Adam, SGD, Adagrad\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "# Import the backend\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAGpqU9iL59N",
        "colab_type": "code",
        "outputId": "2ab0b514-43d0-40e5-b1bb-c1cfa3db4eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "\n",
        "# Prepare to encode group since ANN doesn't like string data in y group.\n",
        "dl_genderfull = gender_full_sampled\n",
        "\n",
        "# Build numerical labels for our models\n",
        "groupencoder = LabelEncoder().fit(dl_genderfull['group'])\n",
        "\n",
        "# Store in a new column\n",
        "dl_genderfull['encoded_group'] = groupencoder.transform(dl_genderfull['group'])\n",
        "\n",
        "dl_genderfull.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>encoded_model</th>\n",
              "      <th>label_id</th>\n",
              "      <th>2</th>\n",
              "      <th>4</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>980</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>993</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "      <th>1002</th>\n",
              "      <th>1003</th>\n",
              "      <th>1005</th>\n",
              "      <th>1006</th>\n",
              "      <th>1007</th>\n",
              "      <th>1008</th>\n",
              "      <th>1009</th>\n",
              "      <th>1010</th>\n",
              "      <th>1011</th>\n",
              "      <th>1012</th>\n",
              "      <th>1013</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>encoded_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7654809</th>\n",
              "      <td>6391094174250536901</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>3722410295315095646</td>\n",
              "      <td>0</td>\n",
              "      <td>857</td>\n",
              "      <td>704</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10659061</th>\n",
              "      <td>-7924701358100587813</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-1596342834117879984</td>\n",
              "      <td>0</td>\n",
              "      <td>863</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8373821</th>\n",
              "      <td>-8930344956501495392</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-3943652190894535955</td>\n",
              "      <td>0</td>\n",
              "      <td>1334</td>\n",
              "      <td>407</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12804025</th>\n",
              "      <td>-7616175892068103491</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-653184325010919369</td>\n",
              "      <td>0</td>\n",
              "      <td>1659</td>\n",
              "      <td>251</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11569255</th>\n",
              "      <td>4585428206812872117</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-8271866350659046570</td>\n",
              "      <td>0</td>\n",
              "      <td>735</td>\n",
              "      <td>774</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    device_id  gender  age  ... 1020  1021  encoded_group\n",
              "7654809   6391094174250536901       1   26  ...    0     0              7\n",
              "10659061 -7924701358100587813       1   26  ...    0     0              7\n",
              "8373821  -8930344956501495392       1   23  ...    0     0              7\n",
              "12804025 -7616175892068103491       1   24  ...    0     0              7\n",
              "11569255  4585428206812872117       1   26  ...    0     0              7\n",
              "\n",
              "[5 rows x 494 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47PyBwTQL84J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Recreate the test and training set since encoded group is now the target.\n",
        "X3 = dl_genderfull.drop(['group'], axis=1)\n",
        "Y3 = dl_genderfull['encoded_group'].values\n",
        "\n",
        "# Instantiate StandardScaler \n",
        "ss = StandardScaler()\n",
        "\n",
        "# Set up the variables.\n",
        "prep_X2 = X3\n",
        "\n",
        "# Standarize and fit the data first \n",
        "stand_x2 = ss.fit_transform(prep_X2)\n",
        "\n",
        "\n",
        "# Create a new training and testing set\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, Y3, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEb5ZLnsMCa6",
        "colab_type": "code",
        "outputId": "fb3e095a-3a71-4d17-c4e0-7e10b94a3166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "source": [
        "# Start with a simple sequential model.\n",
        "model = Sequential()\n",
        "\n",
        "# Add dense layers to create a fully connected MLP\n",
        "# Note that we specify an input shape for the first layer, but only the first layer.\n",
        "# Relu is the activation function used\n",
        "model.add(Dense(128, activation='elu', input_shape=(492,)))\n",
        "# Dropout layers remove features and fight overfitting\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# End with a number of units equal to the number of classes we have for our outcome\n",
        "model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model to put it all together.\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 128)               63104     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 94,476\n",
            "Trainable params: 93,708\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mvesUKpY30n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "history = model.fit(X_train3, y_train3,\n",
        "                    batch_size=1250,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test3, y_test3))\n",
        "\n",
        "score = model.evaluate(X_test3, y_test3, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otmZCt7hqnxN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CRgp95DSrh1",
        "colab_type": "code",
        "outputId": "c70da6a8-f61a-4005-d770-33d55196b5d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Convolutional Neural Network\n",
        "\n",
        "# Create a smaller data set of the previous encoded group.\n",
        "X3_mini = X3[:100000]\n",
        "Y3_mini = Y3[:100000]\n",
        "\n",
        "# Create a new training and testing set again.\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X3_mini, Y3_mini, test_size=0.25)\n",
        "\n",
        "# Increase the dimensional size of X_train/test_pca\n",
        "# in order for Conv1d to run smoothly.\n",
        "X_train_pca_mod = np.expand_dims(X_train4, axis=2)\n",
        "X_test_pca_mod = np.expand_dims(X_test4, axis=2)\n",
        "\n",
        "# Encode y into 12 different vectors for CNN.\n",
        "y_train_CNN = np_utils.to_categorical(y_train4, 12)\n",
        "y_test_CNN = np_utils.to_categorical(y_test4, 12)\n",
        "\n",
        "# Building the Convolutionals Model\n",
        "model = Sequential()\n",
        "\n",
        "# Set up some parameters\n",
        "input_dim = 1\n",
        "\n",
        "# Convert X_train and X_test to numpy array and make sure all sequences\n",
        "# have the same length.\n",
        "max_review_length = 500 \n",
        "X_train_CNN = sequence.pad_sequences(X_train_pca_mod, maxlen=max_review_length) \n",
        "X_test_CNN = sequence.pad_sequences(X_test_pca_mod, maxlen=max_review_length)\n",
        "\n",
        "\n",
        "# First convolutional layer, note the specification of shape\n",
        "model.add(Conv1D(64, kernel_size=10,\n",
        "                 padding='same',\n",
        "                 input_shape=(max_review_length, input_dim),\n",
        "                 activation='elu',\n",
        "                 strides=1))\n",
        "model.add(Conv1D(64, kernel_size=20, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(32, kernel_size=15, activation='elu'))\n",
        "model.add(MaxPooling1D(pool_size=15,\n",
        "                       padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(32, kernel_size=20, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(32, kernel_size=10, activation='elu'))\n",
        "model.add(MaxPooling1D(pool_size=25,\n",
        "                       padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(MaxoutDense(32, nb_feature=12))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxoutDense(32, nb_feature=12))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxoutDense(32, nb_feature=12))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(12, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adagrad(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 500, 64)           704       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 481, 64)           81984     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 481, 64)           256       \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 467, 32)           30752     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 32, 32)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 32, 32)            128       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 32, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 13, 32)            20512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 13, 32)            128       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 4, 32)             10272     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 1, 32)             128       \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "maxout_dense_1 (MaxoutDense) (None, 32)                12672     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "maxout_dense_2 (MaxoutDense) (None, 32)                12672     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "maxout_dense_3 (MaxoutDense) (None, 32)                12672     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 183,660\n",
            "Trainable params: 183,148\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtDicE2QStrz",
        "colab_type": "code",
        "outputId": "ba042a47-6042-4c90-cfa7-40db366b6f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "model.fit(X_train_CNN, y_train_CNN,\n",
        "          batch_size=1250,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test_CNN, y_test_CNN))\n",
        "\n",
        "score = model.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 75000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "75000/75000 [==============================] - 27s 361us/step - loss: 2.2601 - acc: 0.2541 - val_loss: 1.7637 - val_acc: 0.3030\n",
            "Epoch 2/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.7246 - acc: 0.2966 - val_loss: 1.5129 - val_acc: 0.3030\n",
            "Epoch 3/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.5412 - acc: 0.2969 - val_loss: 1.4173 - val_acc: 0.2988\n",
            "Epoch 4/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.4644 - acc: 0.2982 - val_loss: 1.3790 - val_acc: 0.2994\n",
            "Epoch 5/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.4314 - acc: 0.3023 - val_loss: 1.3599 - val_acc: 0.3006\n",
            "Epoch 6/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.4206 - acc: 0.3023 - val_loss: 1.3498 - val_acc: 0.3006\n",
            "Epoch 7/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.4057 - acc: 0.3007 - val_loss: 1.3416 - val_acc: 0.3004\n",
            "Epoch 8/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.3904 - acc: 0.2974 - val_loss: 1.3368 - val_acc: 0.3026\n",
            "Epoch 9/10\n",
            "75000/75000 [==============================] - 21s 275us/step - loss: 1.3834 - acc: 0.2983 - val_loss: 1.3336 - val_acc: 0.3007\n",
            "Epoch 10/10\n",
            "75000/75000 [==============================] - 21s 276us/step - loss: 1.3781 - acc: 0.2982 - val_loss: 1.3307 - val_acc: 0.2997\n",
            "Test loss: 1.3306851333999634\n",
            "Test accuracy: 0.29956\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pIYv8mz3qEB",
        "colab_type": "text"
      },
      "source": [
        "# Using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kp-L7Nu390L",
        "colab_type": "code",
        "outputId": "014aedf4-87c3-4445-884f-23bf069f10b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# Prepare to encode group since ANN doesn't like string data in y group.\n",
        "dl_genderfull = gender_full_sampled\n",
        "\n",
        "# Build numerical labels for our models\n",
        "groupencoder = LabelEncoder().fit(dl_genderfull['group'])\n",
        "\n",
        "# Store in a new column\n",
        "dl_genderfull['encoded_group'] = groupencoder.transform(dl_genderfull['group'])\n",
        "\n",
        "dl_genderfull.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>device_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>group</th>\n",
              "      <th>app_id</th>\n",
              "      <th>is_active</th>\n",
              "      <th>encoded_model</th>\n",
              "      <th>label_id</th>\n",
              "      <th>2</th>\n",
              "      <th>4</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>974</th>\n",
              "      <th>975</th>\n",
              "      <th>976</th>\n",
              "      <th>977</th>\n",
              "      <th>978</th>\n",
              "      <th>980</th>\n",
              "      <th>982</th>\n",
              "      <th>983</th>\n",
              "      <th>984</th>\n",
              "      <th>986</th>\n",
              "      <th>987</th>\n",
              "      <th>988</th>\n",
              "      <th>990</th>\n",
              "      <th>991</th>\n",
              "      <th>993</th>\n",
              "      <th>995</th>\n",
              "      <th>996</th>\n",
              "      <th>997</th>\n",
              "      <th>998</th>\n",
              "      <th>999</th>\n",
              "      <th>1002</th>\n",
              "      <th>1003</th>\n",
              "      <th>1005</th>\n",
              "      <th>1006</th>\n",
              "      <th>1007</th>\n",
              "      <th>1008</th>\n",
              "      <th>1009</th>\n",
              "      <th>1010</th>\n",
              "      <th>1011</th>\n",
              "      <th>1012</th>\n",
              "      <th>1013</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>encoded_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6530707</th>\n",
              "      <td>3815308419818425750</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-5305727755345208179</td>\n",
              "      <td>1</td>\n",
              "      <td>129</td>\n",
              "      <td>704</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6735035</th>\n",
              "      <td>1570955105239258370</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-3507529970483852351</td>\n",
              "      <td>0</td>\n",
              "      <td>865</td>\n",
              "      <td>254</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8718114</th>\n",
              "      <td>-1030061935764942114</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>1757044000527607662</td>\n",
              "      <td>0</td>\n",
              "      <td>375</td>\n",
              "      <td>1012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10093908</th>\n",
              "      <td>-5641386176120876758</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-4986139885405704</td>\n",
              "      <td>0</td>\n",
              "      <td>736</td>\n",
              "      <td>405</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275162</th>\n",
              "      <td>2957948755409153401</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>M23-26</td>\n",
              "      <td>-5720078949152207372</td>\n",
              "      <td>1</td>\n",
              "      <td>1247</td>\n",
              "      <td>721</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 494 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    device_id  gender  age  ... 1020  1021  encoded_group\n",
              "6530707   3815308419818425750       1   23  ...    0     0              7\n",
              "6735035   1570955105239258370       1   24  ...    0     0              7\n",
              "8718114  -1030061935764942114       1   25  ...    0     0              7\n",
              "10093908 -5641386176120876758       1   26  ...    0     0              7\n",
              "275162    2957948755409153401       1   23  ...    0     0              7\n",
              "\n",
              "[5 rows x 494 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWnJHmZp56-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Recreate the test and training set since encoded group is now the target.\n",
        "X3 = resampled2.drop(['group'], axis=1)\n",
        "Y3 = resampled2['encoded_group'].values\n",
        "\n",
        "# Instantiate StandardScaler for pca\n",
        "ss = StandardScaler()\n",
        "\n",
        "# Set up the variables.\n",
        "prep_X2 = X3\n",
        "\n",
        "# Standarize and fit the data first \n",
        "stand_x2 = ss.fit_transform(prep_X2)\n",
        "\n",
        "# Perform PCA on the standardized data. \n",
        "#X3_pca = pca.fit_transform(stand_x2)\n",
        "pca = PCA(n_components=10)\n",
        "principalComponents = pca.fit_transform(stand_x2)\n",
        "\n",
        "\n",
        "# Create a new training and testing set\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(principalComponents, Y3, test_size=0.25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvlskfjM7oMJ",
        "colab_type": "code",
        "outputId": "4829e095-b2a0-4f56-d949-3960439b0f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        }
      },
      "source": [
        "# Start with a simple sequential model.\n",
        "model = Sequential()\n",
        "\n",
        "# Add dense layers to create a fully connected MLP\n",
        "# Note that we specify an input shape for the first layer, but only the first layer.\n",
        "# Relu is the activation function used\n",
        "model.add(Dense(128, activation='elu', input_shape=(10,)))\n",
        "# Dropout layers remove features and fight overfitting\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# End with a number of units equal to the number of classes we have for our outcome\n",
        "model.add(Dense(12, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model to put it all together.\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_11 (Dense)             (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 12)                780       \n",
            "=================================================================\n",
            "Total params: 32,780\n",
            "Trainable params: 32,012\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISscgpYI791p",
        "colab_type": "code",
        "outputId": "26e03d69-18f7-48b5-8de6-f97376301ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "history = model.fit(X_train3, y_train3,\n",
        "                    batch_size=1250,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    validation_data=(X_test3, y_test3))\n",
        "\n",
        "score = model.evaluate(X_test3, y_test3, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 270000 samples, validate on 90000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "270000/270000 [==============================] - 11s 42us/step - loss: 1.8614 - acc: 0.2932 - val_loss: 1.3208 - val_acc: 0.4219\n",
            "Epoch 2/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 1.3024 - acc: 0.4315 - val_loss: 0.9493 - val_acc: 0.5853\n",
            "Epoch 3/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 1.1751 - acc: 0.4850 - val_loss: 0.9430 - val_acc: 0.5929\n",
            "Epoch 4/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 1.1125 - acc: 0.5153 - val_loss: 0.9113 - val_acc: 0.5996\n",
            "Epoch 5/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 1.0774 - acc: 0.5313 - val_loss: 0.8798 - val_acc: 0.6185\n",
            "Epoch 6/20\n",
            "270000/270000 [==============================] - 5s 17us/step - loss: 1.0513 - acc: 0.5439 - val_loss: 0.8716 - val_acc: 0.6134\n",
            "Epoch 7/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 1.0312 - acc: 0.5525 - val_loss: 0.8498 - val_acc: 0.6305\n",
            "Epoch 8/20\n",
            "270000/270000 [==============================] - 4s 17us/step - loss: 1.0159 - acc: 0.5601 - val_loss: 0.8611 - val_acc: 0.6198\n",
            "Epoch 9/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 1.0048 - acc: 0.5646 - val_loss: 0.8383 - val_acc: 0.6289\n",
            "Epoch 10/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.9890 - acc: 0.5721 - val_loss: 0.8230 - val_acc: 0.6413\n",
            "Epoch 11/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.9790 - acc: 0.5769 - val_loss: 0.8110 - val_acc: 0.6483\n",
            "Epoch 12/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.9683 - acc: 0.5833 - val_loss: 0.8003 - val_acc: 0.6580\n",
            "Epoch 13/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.9563 - acc: 0.5889 - val_loss: 0.8098 - val_acc: 0.6438\n",
            "Epoch 14/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.9427 - acc: 0.5959 - val_loss: 0.7646 - val_acc: 0.6799\n",
            "Epoch 15/20\n",
            "270000/270000 [==============================] - 5s 17us/step - loss: 0.9282 - acc: 0.6058 - val_loss: 0.7517 - val_acc: 0.6886\n",
            "Epoch 16/20\n",
            "270000/270000 [==============================] - 5s 17us/step - loss: 0.9147 - acc: 0.6124 - val_loss: 0.7256 - val_acc: 0.7108\n",
            "Epoch 17/20\n",
            "270000/270000 [==============================] - 5s 17us/step - loss: 0.9020 - acc: 0.6198 - val_loss: 0.7084 - val_acc: 0.7155\n",
            "Epoch 18/20\n",
            "270000/270000 [==============================] - 4s 17us/step - loss: 0.8880 - acc: 0.6281 - val_loss: 0.6886 - val_acc: 0.7306\n",
            "Epoch 19/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.8771 - acc: 0.6340 - val_loss: 0.6757 - val_acc: 0.7449\n",
            "Epoch 20/20\n",
            "270000/270000 [==============================] - 4s 16us/step - loss: 0.8671 - acc: 0.6383 - val_loss: 0.6730 - val_acc: 0.7455\n",
            "Test loss: 0.6729799430423312\n",
            "Test accuracy: 0.7454888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNWp6mqb9fFl",
        "colab_type": "code",
        "outputId": "9b3f417e-dbdc-4d2d-e58a-0a53271a6c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        }
      },
      "source": [
        "#Convolutional Neural Network\n",
        "\n",
        "\n",
        "# Recreate the test and training set since encoded group is now the target.\n",
        "X3 = dl_genderfull.drop(['group'], axis=1)\n",
        "Y3 = dl_genderfull['encoded_group'].values\n",
        "\n",
        "# Instantiate StandardScaler for pca\n",
        "ss = StandardScaler()\n",
        "\n",
        "# Set up the variables.\n",
        "prep_X2 = X3\n",
        "\n",
        "# Standarize and fit the data first \n",
        "stand_x2 = ss.fit_transform(prep_X2)\n",
        "\n",
        "# Perform PCA on the standardized data. \n",
        "pca = PCA(n_components=10)\n",
        "principalComponents = pca.fit_transform(stand_x2)\n",
        "\n",
        "\n",
        "# Create a new training and testing set again.\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(principalComponents, Y3, test_size=0.25)\n",
        "\n",
        "# Increase the dimensional size of X_train/test_pca\n",
        "# in order for Conv1d to run smoothly.\n",
        "X_train_pca_mod = np.expand_dims(X_train4, axis=2)\n",
        "X_test_pca_mod = np.expand_dims(X_test4, axis=2)\n",
        "\n",
        "# Encode y into 12 different vectors for CNN.\n",
        "y_train_CNN = np_utils.to_categorical(y_train4, 12)\n",
        "y_test_CNN = np_utils.to_categorical(y_test4, 12)\n",
        "\n",
        "# Building the Convolutionals Model\n",
        "model = Sequential()\n",
        "\n",
        "# Set up some parameters\n",
        "input_dim = 1\n",
        "\n",
        "# Convert X_train and X_test to numpy array and make sure all sequences\n",
        "# have the same length.\n",
        "max_review_length = 500 \n",
        "X_train_CNN = sequence.pad_sequences(X_train_pca_mod, maxlen=max_review_length) \n",
        "X_test_CNN = sequence.pad_sequences(X_test_pca_mod, maxlen=max_review_length)\n",
        "\n",
        "\n",
        "# First convolutional layer, note the specification of shape\n",
        "model.add(Conv1D(64, kernel_size=10,\n",
        "                 padding='same',\n",
        "                 input_shape=(max_review_length, input_dim),\n",
        "                 activation='elu',\n",
        "                 strides=1))\n",
        "model.add(Conv1D(64, kernel_size=20, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(32, kernel_size=15, activation='elu'))\n",
        "model.add(MaxPooling1D(pool_size=15,\n",
        "                       padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(32, kernel_size=20, activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv1D(32, kernel_size=10, activation='elu'))\n",
        "model.add(MaxPooling1D(pool_size=25,\n",
        "                       padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(MaxoutDense(32, nb_feature=12))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxoutDense(32, nb_feature=12))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxoutDense(32, nb_feature=12))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(12, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adagrad(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_6 (Conv1D)            (None, 500, 64)           704       \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 481, 64)           81984     \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 481, 64)           256       \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 467, 32)           30752     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 32, 32)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 32, 32)            128       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 32, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 13, 32)            20512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 13, 32)            128       \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 4, 32)             10272     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 1, 32)             128       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 1, 32)             0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "maxout_dense_4 (MaxoutDense) (None, 32)                12672     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "maxout_dense_5 (MaxoutDense) (None, 32)                12672     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "maxout_dense_6 (MaxoutDense) (None, 32)                12672     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 183,660\n",
            "Trainable params: 183,148\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvJZH_EBEXk3",
        "colab_type": "code",
        "outputId": "2eb4db0e-a6d7-4932-c5b4-9b8fa917ca34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "model.fit(X_train_CNN, y_train_CNN,\n",
        "          batch_size=1250,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test_CNN, y_test_CNN))\n",
        "\n",
        "score = model.evaluate(X_test_CNN, y_test_CNN, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 270000 samples, validate on 90000 samples\n",
            "Epoch 1/10\n",
            "270000/270000 [==============================] - 77s 284us/step - loss: 2.1951 - acc: 0.1965 - val_loss: 14.7762 - val_acc: 0.0833\n",
            "Epoch 2/10\n",
            "270000/270000 [==============================] - 73s 272us/step - loss: 1.7934 - acc: 0.2780 - val_loss: 14.7762 - val_acc: 0.0833\n",
            "Epoch 3/10\n",
            "270000/270000 [==============================] - 73s 272us/step - loss: 1.7109 - acc: 0.2938 - val_loss: 14.7762 - val_acc: 0.0833\n",
            "Epoch 4/10\n",
            "270000/270000 [==============================] - 74s 273us/step - loss: 1.6723 - acc: 0.3044 - val_loss: 14.7675 - val_acc: 0.0833\n",
            "Epoch 5/10\n",
            "270000/270000 [==============================] - 74s 273us/step - loss: 1.6476 - acc: 0.3128 - val_loss: 1.7392 - val_acc: 0.2974\n",
            "Epoch 6/10\n",
            "270000/270000 [==============================] - 74s 273us/step - loss: 1.6323 - acc: 0.3155 - val_loss: 14.7762 - val_acc: 0.0833\n",
            "Epoch 7/10\n",
            "270000/270000 [==============================] - 74s 272us/step - loss: 1.6205 - acc: 0.3199 - val_loss: 14.7762 - val_acc: 0.0833\n",
            "Epoch 8/10\n",
            "270000/270000 [==============================] - 74s 273us/step - loss: 1.6108 - acc: 0.3225 - val_loss: 2.6154 - val_acc: 0.2187\n",
            "Epoch 9/10\n",
            "270000/270000 [==============================] - 74s 274us/step - loss: 1.6019 - acc: 0.3248 - val_loss: 1.5590 - val_acc: 0.3334\n",
            "Epoch 10/10\n",
            "270000/270000 [==============================] - 74s 274us/step - loss: 1.5960 - acc: 0.3284 - val_loss: 13.1495 - val_acc: 0.0833\n",
            "Test loss: 13.149502387661403\n",
            "Test accuracy: 0.08325555555555555\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}